<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>dik&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-04-24T14:11:10.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>dik</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>大数据入门10-Yarn总结</title>
    <link href="http://yoursite.com/2019/04/24/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A810-Yarn%E6%80%BB%E7%BB%93/"/>
    <id>http://yoursite.com/2019/04/24/大数据入门10-Yarn总结/</id>
    <published>2019-04-24T14:11:10.000Z</published>
    <updated>2019-04-24T14:11:10.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><p><img src="https://" alt="" style="width:100%"></p><a id="more"></a><h1 id=""><a href="#" class="headerlink" title="#"></a>#</h1><h1 id="-1"><a href="#-1" class="headerlink" title="#"></a>#</h1><h1 id="-2"><a href="#-2" class="headerlink" title="#"></a>#</h1><hr>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>大数据入门09-HDFS总结</title>
    <link href="http://yoursite.com/2019/01/14/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A809-HDFS%E6%80%BB%E7%BB%93/"/>
    <id>http://yoursite.com/2019/01/14/大数据入门09-HDFS总结/</id>
    <published>2019-01-14T10:11:16.000Z</published>
    <updated>2019-04-24T14:09:41.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><p><img src="https://" alt="" style="width:100%"></p><a id="more"></a><h2 id="HDFS概述"><a href="#HDFS概述" class="headerlink" title="HDFS概述"></a>HDFS概述</h2><p>HDFS（Hadoop Distributed File System），它是一个文件系统，用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。<br>HDFS的使用场景：适合一次写入，多次读出的场景，且不支持文件的修改。适合用来做数据分析，并不适合用来做网盘应用。</p><h3 id="HDFS优缺点"><a href="#HDFS优缺点" class="headerlink" title="HDFS优缺点"></a>HDFS优缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul><li><p>高容错性<br>1)数据自动保存多个副本。它通过增加副本的形式，提高容错性<br>2)某一个副本丢失以后，它可以自动恢复</p></li><li><p>适合处理大数据<br>1)数据规模：能够处理数据规模达到GB、TB、甚至PB级别的数据<br>2)文件规模：能够处理百万规模以上的文件数量，数量相当之大</p></li><li><p>可构建在廉价机器上，通过多副本机制，提高可靠性</p></li></ul><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul><li><p>不适合低延时数据访问，比如毫秒级的存储数据，是做不到的</p></li><li><p>无法高效的对大量小文件进行存储<br>1)存储大量小文件的话，它会占用NameNode大量的内存来存储文件目录和块信息。这样是不可取的，因为NameNode的内存总是有限的<br>2)小文件存储的寻址时间会超过读取时间，它违反了HDFS的设计目标</p></li><li><p>不支持并发写入、文件随机修改<br>1)一个文件只能有一个写，不允许多个线程同时写<br>2)仅支持数据append（追加），不支持文件的随机修改</p></li></ul><h3 id="HDFS组成架构"><a href="#HDFS组成架构" class="headerlink" title="HDFS组成架构"></a>HDFS组成架构</h3><p>1) NameNode（nn）：就是Master，它是一个主管、管理者。</p><ul><li>管理HDFS的名称空间</li><li>配置副本策略</li><li>管理数据块（Block）映射信息</li><li>处理客户端读写请求</li></ul><p>2) DataNode：就是Slave。NameNode下达命令，DataNode执行实际的操作</p><ul><li>存储实际的数据块</li><li>执行数据块的读/写操作</li></ul><p>3) Client：就是客户端</p><ul><li>文件切分。文件上传HDFS的时候，Client将文件切分成一个一个的Block，然后进行上传</li><li>与NameNode交互，获取文件的位置信息</li><li>与DataNode交互，读取或者写入数据</li><li>Client提供一些命令来管理HDFS，比如NameNode格式化</li><li>Client可以通过一些命令来访问HDFS，比如对HDFS增删查改操作</li></ul><p>4) Secondary NameNode：并非NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务</p><ul><li>辅助NameNode，分担其工作量，比如定期合并Fsimage和Edits，并推送给NameNode </li><li>在紧急情况下，可辅助恢复NameNode</li></ul><h2 id="HDFS的常用Shell操作"><a href="#HDFS的常用Shell操作" class="headerlink" title="HDFS的常用Shell操作"></a>HDFS的常用Shell操作</h2><h3 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h3><p>bin/hadoop fs 具体命令   OR  bin/hdfs dfs 具体命令<br>dfs是fs的实现类</p><h3 id="命令大全"><a href="#命令大全" class="headerlink" title="命令大全"></a>命令大全</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">[-appendToFile &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">        [-cat [-ignoreCrc] &lt;src&gt; ...]</span><br><span class="line">        [-checksum &lt;src&gt; ...]</span><br><span class="line">        [-chgrp [-R] GROUP PATH...]</span><br><span class="line">        [-chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...]</span><br><span class="line">        [-chown [-R] [OWNER][:[GROUP]] PATH...]</span><br><span class="line">        [-copyFromLocal [-f] [-p] &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">        [-copyToLocal [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</span><br><span class="line">        [-count [-q] &lt;path&gt; ...]</span><br><span class="line">        [-cp [-f] [-p] &lt;src&gt; ... &lt;dst&gt;]</span><br><span class="line">        [-createSnapshot &lt;snapshotDir&gt; [&lt;snapshotName&gt;]]</span><br><span class="line">        [-deleteSnapshot &lt;snapshotDir&gt; &lt;snapshotName&gt;]</span><br><span class="line">        [-df [-h] [&lt;path&gt; ...]]</span><br><span class="line">        [-du [-s] [-h] &lt;path&gt; ...]</span><br><span class="line">        [-expunge]</span><br><span class="line">        [-get [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</span><br><span class="line">        [-getfacl [-R] &lt;path&gt;]</span><br><span class="line">        [-getmerge [-nl] &lt;src&gt; &lt;localdst&gt;]</span><br><span class="line">        [-help [cmd ...]]</span><br><span class="line">        [-ls [-d] [-h] [-R] [&lt;path&gt; ...]]</span><br><span class="line">        [-mkdir [-p] &lt;path&gt; ...]</span><br><span class="line">        [-moveFromLocal &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">        [-moveToLocal &lt;src&gt; &lt;localdst&gt;]</span><br><span class="line">        [-mv &lt;src&gt; ... &lt;dst&gt;]</span><br><span class="line">        [-put [-f] [-p] &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">        [-renameSnapshot &lt;snapshotDir&gt; &lt;oldName&gt; &lt;newName&gt;]</span><br><span class="line">        [-rm [-f] [-r|-R] [-skipTrash] &lt;src&gt; ...]</span><br><span class="line">        [-rmdir [--ignore-fail-on-non-empty] &lt;dir&gt; ...]</span><br><span class="line">        [-setfacl [-R] [&#123;-b|-k&#125; &#123;-m|-x &lt;acl_spec&gt;&#125; &lt;path&gt;]|[--set &lt;acl_spec&gt; &lt;path&gt;]]</span><br><span class="line">        [-setrep [-R] [-w] &lt;rep&gt; &lt;path&gt; ...]</span><br><span class="line">        [-stat [format] &lt;path&gt; ...]</span><br><span class="line">        [-tail [-f] &lt;file&gt;]</span><br><span class="line">        [-test -[defsz] &lt;path&gt;]</span><br><span class="line">        [-text [-ignoreCrc] &lt;src&gt; ...]</span><br><span class="line">        [-touchz &lt;path&gt; ...]</span><br><span class="line">        [-usage [cmd ...]]</span><br></pre></td></tr></table></figure><h3 id="常用命令实操"><a href="#常用命令实操" class="headerlink" title="常用命令实操"></a>常用命令实操</h3><ul><li>-help：输出这个命令参数<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -help rm</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-rm [-f] [-r|-R] [-skipTrash] &lt;src&gt; ... :</span><br><span class="line">  Delete all files that match the specified file pattern. Equivalent to the Unix</span><br><span class="line">  command &quot;rm &lt;src&gt;&quot;</span><br><span class="line">                                                                                 </span><br><span class="line">  -skipTrash  option bypasses trash, if enabled, and immediately deletes &lt;src&gt;   </span><br><span class="line">  -f          If the file does not exist, do not display a diagnostic message or </span><br><span class="line">              modify the exit status to reflect an error.                        </span><br><span class="line">  -[rR]       Recursively deletes directories</span><br></pre></td></tr></table></figure><ul><li>-ls: 显示目录信息<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls /</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Found 5 items</span><br><span class="line">-rw-r--r--   3 root supergroup       1366 2019-02-15 15:33 /README.txt</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2019-02-21 14:20 /directory</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2019-02-18 10:09 /hadoop</span><br><span class="line">drwxrwxr-x   - root supergroup          0 2019-02-20 16:24 /tmp</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2019-02-27 11:48 /user</span><br></pre></td></tr></table></figure><ul><li>-mkdir：在HDFS上创建目录<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir -p /sanguo/shuguo</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190416174323.png" alt=""></p><ul><li>-moveFromLocal：从本地剪切粘贴到HDFS<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">touch kongming.txt</span><br><span class="line">hadoop fs -moveFromLocal ./kongming.txt /sanguo/shuguo</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190416174603.png" alt=""></p><ul><li><p>-appendToFile：追加一个文件到已经存在的文件末尾</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">touch liubei.txt</span><br><span class="line">vim liubei.txt</span><br><span class="line">hadoop fs -appendToFile liubei.txt /sanguo/shuguo/kongming.txt</span><br></pre></td></tr></table></figure></li><li><p>-cat：显示文件内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat /sanguo/shuguo/kongming.txt</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190416175122.png" alt=""></p><ul><li><p>-chgrp 、-chmod、-chown：Linux文件系统中的用法一样，修改文件所属权限</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs  -chmod  666  /sanguo/shuguo/kongming.txt</span><br><span class="line">hadoop fs  -chown  atguigu:atguigu   /sanguo/shuguo/kongming.txt</span><br></pre></td></tr></table></figure></li><li><p>-copyFromLocal：从本地文件系统中拷贝文件到HDFS路径去</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyFromLocal NOTICE.txt /</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190416175646.png" alt=""></p><ul><li><p>-copyToLocal：从HDFS拷贝到本地</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyToLocal /sanguo/shuguo/kongming.txt ./</span><br></pre></td></tr></table></figure></li><li><p>-cp ：从HDFS的一个路径拷贝到HDFS的另一个路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cp /sanguo/shuguo/kongming.txt /zhuge.txt</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190416181455.png" alt=""></p><ul><li>-mv：在HDFS目录中移动文件<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mv /zhuge.txt /sanguo/shuguo/</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190416181749.png" alt=""></p><ul><li>-getmerge：合并下载多个文件，比如HDFS的目录 /user/atguigu/test下有多个文件:log.1, log.2,log.3,…</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -getmerge /sanguo/shuguo/* ./zaiyiqi.txt</span><br></pre></td></tr></table></figure><ul><li><p>-get：等同于copyToLocal，就是从HDFS下载文件到本地</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -get /sanguo/shuguo/kongming.txt ./</span><br></pre></td></tr></table></figure></li><li><p>-put：等同于copyFromLocal</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put ./zaiyiqi.txt /user/</span><br></pre></td></tr></table></figure><ul><li><p>-rm：删除文件或文件夹</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -rm /user/zaiyiqi.txt</span><br></pre></td></tr></table></figure></li><li><p>-du统计文件夹的大小信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -du -s -h /user</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190416182500.png" alt=""></p><h2 id="HDFS的数据流"><a href="#HDFS的数据流" class="headerlink" title="HDFS的数据流"></a>HDFS的数据流</h2><h3 id="HDFS写数据流程"><a href="#HDFS写数据流程" class="headerlink" title="HDFS写数据流程"></a>HDFS写数据流程</h3><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190417152653.png" alt=""></p><ul><li>客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在</li><li>NameNode返回是否可以上传</li><li>客户端请求第一个 Block上传到哪几个DataNode服务器上</li><li>NameNode返回3个DataNode节点，分别为dn1,dn2,dn3</li><li>客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成</li><li>dn1、dn2、dn3逐级应答客户端</li><li>客户端开始往dn1上传第一个Block（先从磁盘读取数据放到一个本地内存缓存），以Packet为单位，dn1收到一个Packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答</li><li>当一个Block传输完成之后，客户端再次请求NameNode上传第二个Block的服务器。（重复执行3-7步）</li></ul><h3 id="HDFS读数据流程"><a href="#HDFS读数据流程" class="headerlink" title="HDFS读数据流程"></a>HDFS读数据流程</h3><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190423163351.png" alt=""></p><ul><li>客户端通过Distributed FileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址</li><li>挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据</li><li>DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以Packet为单位来做校验）</li><li>客户端以Packet为单位接收，先在本地缓存，然后写入目标文件</li></ul><h2 id="SecondaryNameNode和NameNode"><a href="#SecondaryNameNode和NameNode" class="headerlink" title="SecondaryNameNode和NameNode"></a>SecondaryNameNode和NameNode</h2><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190423173551.png" alt=""></p><h3 id="第一阶段：NameNode启动"><a href="#第一阶段：NameNode启动" class="headerlink" title="第一阶段：NameNode启动"></a>第一阶段：NameNode启动</h3><ul><li>第一次启动NameNode格式化后，创建Fsimage和Edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存</li><li>客户端对元数据进行增删改的请求</li><li>NameNode记录操作日志，更新滚动日志</li><li>NameNode在内存中对数据进行增删改</li></ul><h3 id="第二阶段：Secondary-NameNode工作"><a href="#第二阶段：Secondary-NameNode工作" class="headerlink" title="第二阶段：Secondary NameNode工作"></a>第二阶段：Secondary NameNode工作</h3><ul><li>Secondary NameNode询问NameNode是否需要CheckPoint。直接带回NameNode是否检查结果</li><li>Secondary NameNode请求执行CheckPoint</li><li>NameNode滚动正在写的Edits日志</li><li>将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode</li><li>Secondary NameNode加载编辑日志和镜像文件到内存，并合并</li><li>生成新的镜像文件fsimage.chkpoint</li><li>拷贝fsimage.chkpoint到NameNode</li><li>NameNode将fsimage.chkpoint重新命名成fsimage</li></ul><h2 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h2><h3 id="DataNode工作机制"><a href="#DataNode工作机制" class="headerlink" title="DataNode工作机制"></a>DataNode工作机制</h3><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190423181910.png" alt=""></p><ul><li>一个数据块在DataNode上以文件形式存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据包括数据块的长度，块数据的校验和，以及时间戳</li><li>DataNode启动后向NameNode注册，通过后，周期性（1小时）的向NameNode上报所有的块信息</li><li>心跳是每3秒一次，心跳返回结果带有NameNode给该DataNode的命令如复制块数据到另一台机器，或删除某个数据块。如果超过10分钟没有收到某个DataNode的心跳，则认为该节点不可用</li><li>集群运行中可以安全加入和退出一些机器<hr></li></ul>]]></content>
    
    <summary type="html">
    
      这是大数据入门的第九篇文章
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="HDFS" scheme="http://yoursite.com/tags/HDFS/"/>
    
  </entry>
  
  <entry>
    <title>大数据入门08-HIVE常用DDL操作</title>
    <link href="http://yoursite.com/2019/01/05/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A808-HIVE%E5%B8%B8%E7%94%A8DDL%E6%93%8D%E4%BD%9C/"/>
    <id>http://yoursite.com/2019/01/05/大数据入门08-HIVE常用DDL操作/</id>
    <published>2019-01-05T02:42:18.000Z</published>
    <updated>2019-04-14T10:13:14.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><p><img src="https://" alt="" style="width:100%"></p><a id="more"></a><h2 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h2><ul><li>创建一个数据库，数据库在 HDFS 上的默认存储路径是/user/hive/warehouse/*.db。 </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create database db_hive;</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190324115057.png" alt=""></p><ul><li>避免要创建的数据库已经存在错误，增加 if not exists 判断。（标准写法） </li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span> db_hive;</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190324115225.png" alt=""></p><ul><li>创建一个数据库，指定数据库在 HDFS 上存放的位置 </li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> db_hive2 location <span class="string">'/db_hive2.db'</span>;</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190324115344.png" alt=""></p><h2 id="修改数据库"><a href="#修改数据库" class="headerlink" title="修改数据库"></a>修改数据库</h2><p>用户可以使用 ALTER DATABASE 命令为某个数据库的 DBPROPERTIES 设置键-值对<br>属性值，来描述这个数据库的属性信息。<strong>数据库的其他元数据信息都是不可更改的，包括数<br>据库名和数据库所在的目录位置。</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter database db_hive set dbproperties(&apos;createtime&apos;=&apos;20190101&apos;);</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190324115923.png" alt=""></p><h2 id="查询数据库"><a href="#查询数据库" class="headerlink" title="查询数据库"></a>查询数据库</h2><h3 id="查看数据库详情"><a href="#查看数据库详情" class="headerlink" title="查看数据库详情"></a>查看数据库详情</h3><ul><li>显示数据库信息 </li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">desc database db_hive;</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190324120548.png" alt=""></p><ul><li>显示数据库详细信息，extended</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">desc database extended db_hive;</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190324121207.png" alt=""></p><h3 id="切换当前数据库"><a href="#切换当前数据库" class="headerlink" title="切换当前数据库"></a>切换当前数据库</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> db_hive;</span><br></pre></td></tr></table></figure><h2 id="删除数据库"><a href="#删除数据库" class="headerlink" title="删除数据库"></a>删除数据库</h2><ul><li>删除空数据库</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">database</span> db_hive2;</span><br></pre></td></tr></table></figure><ul><li>如果删除的数据库不存在，最好采用 if exists 判断数据库是否存在 </li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">database</span> <span class="keyword">if</span> <span class="keyword">exists</span> db_hive2;</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190324122021.png" alt=""></p><ul><li>如果数据库不为空，可以采用 cascade 命令，强制删除 </li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">database</span> db_hive <span class="keyword">cascade</span>;</span><br></pre></td></tr></table></figure><h2 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h2><p>建表语法:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> [<span class="keyword">EXTERNAL</span>] <span class="keyword">TABLE</span> [<span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] table_name  </span><br><span class="line">[(col_name data_type [<span class="keyword">COMMENT</span> col_comment], ...)]  </span><br><span class="line">[<span class="keyword">COMMENT</span> table_comment]  </span><br><span class="line">[PARTITIONED <span class="keyword">BY</span> (col_name data_type [<span class="keyword">COMMENT</span> col_comment], ...)]  </span><br><span class="line">[CLUSTERED <span class="keyword">BY</span> (col_name, col_name, ...)  </span><br><span class="line">[SORTED <span class="keyword">BY</span> (col_name [<span class="keyword">ASC</span>|<span class="keyword">DESC</span>], ...)] <span class="keyword">INTO</span> num_buckets BUCKETS]  </span><br><span class="line">[<span class="keyword">ROW</span> <span class="keyword">FORMAT</span> row_format]  </span><br><span class="line">[<span class="keyword">STORED</span> <span class="keyword">AS</span> file_format]  </span><br><span class="line">[LOCATION hdfs_path]</span><br></pre></td></tr></table></figure><ul><li>CREATE TABLE 创建一个指定名字的表。如果相同名字的表已经存在，则抛出<br>异常；用户可以用 IF NOT EXISTS 选项来忽略这个异常。</li><li>EXTERNAL 关键字可以让用户创建一个外部表，在建表的同时指定一个指向实际<br>数据的路径（LOCATION），Hive 创建内部表时，会将数据移动到数据仓库指向的路<br>径；若创建外部表，仅记录数据所在的路径，不对数据的位置做任何改变。在删除表的<br>时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据。 </li><li>COMMENT：为表和列添加注释。 </li><li>PARTITIONED BY 创建分区表 </li><li>CLUSTERED BY 创建分桶表</li><li>SORTED BY 不常用 </li><li><p>ROW FORMAT<br>DELIMITED [FIELDS TERMINATED BY char] [COLLECTION ITEMS TERMINATED BY char]<br>[MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]<br>| SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, …)]<br>用户在建表的时候可以自定义 SerDe 或者使用自带的 SerDe。如果没有指定 ROW FORMAT 或者 ROW FORMAT DELIMITED，将会使用自带的 SerDe。在建表的时候，<br>用户还需要为表指定列，用户在指定表的列的同时也会指定自定义的 SerDe，Hive 通过 SerDe 确定表的具体的列的数据。<br><em>SerDe是Serialize/Deserilize的简称，目的是用于序列化和反序列化。</em></p></li><li><p>STORED AS 指定存储文件类型<br>常用的存储文件类型：SEQUENCEFILE（二进制序列文件）、TEXTFILE（文本）、<br>RCFILE（列式存储格式文件）<br>如果文件数据是纯文本，可以使用 STORED AS TEXTFILE。如果数据需要压缩，<br>使用 STORED AS SEQUENCEFILE。</p></li><li><p>LOCATION ：指定表在 HDFS 上的存储位置.</p></li><li>LIKE 允许用户复制现有的表结构，但是不复制数据.</li></ul><h3 id="管理表-内部表"><a href="#管理表-内部表" class="headerlink" title="管理表(内部表)"></a>管理表(内部表)</h3><p>默认创建的表都是所谓的管理表，有时也被称为内部表。因为这种表，Hive 会（或多<br>或少地）控制着数据的生命周期。Hive 默认情况下会将这些表的数据存储在由配置项<br>hive.metastore.warehouse.dir(例如，/user/hive/warehouse)所定义的目录的子目录下。 当我们<br>删除一个管理表时，Hive 也会删除这个表中数据。管理表不适合和其他工具共享数据。 </p><ul><li>普通创建表 </li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span> student2( <span class="keyword">id</span> <span class="built_in">int</span>, <span class="keyword">name</span> <span class="keyword">string</span> ) </span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span> </span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> textfile </span><br><span class="line">location <span class="string">'/user/hive/warehouse/student2'</span>;</span><br></pre></td></tr></table></figure><ul><li>根据查询结果创建表（查询的结果会添加到新创建的表中）</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span> student3 </span><br><span class="line"><span class="keyword">as</span> <span class="keyword">select</span> <span class="keyword">id</span>, <span class="keyword">name</span> <span class="keyword">from</span> student;</span><br></pre></td></tr></table></figure><ul><li>根据已经存在的表结构创建表 </li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span> student4 <span class="keyword">like</span> student;</span><br></pre></td></tr></table></figure><ul><li>查询表的类型 </li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">desc formatted student2;</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190324155054.png" alt=""></p><h3 id="外部表"><a href="#外部表" class="headerlink" title="外部表"></a>外部表</h3><ul><li>建表语句<br>创建部门表 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span> default.dept( </span><br><span class="line">    deptno <span class="built_in">int</span>, </span><br><span class="line">    dname <span class="keyword">string</span>, </span><br><span class="line">    loc <span class="built_in">int</span> ) </span><br><span class="line">    <span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>;</span><br></pre></td></tr></table></figure></li></ul><p>创建员工表</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span> default.emp( </span><br><span class="line">    empno <span class="built_in">int</span>, </span><br><span class="line">    ename <span class="keyword">string</span>, </span><br><span class="line">    job <span class="keyword">string</span>, </span><br><span class="line">    mgr <span class="built_in">int</span>, </span><br><span class="line">    hiredate <span class="keyword">string</span>,  </span><br><span class="line">    sal <span class="keyword">double</span>,  </span><br><span class="line">    comm <span class="keyword">double</span>, </span><br><span class="line">    deptno <span class="built_in">int</span>) </span><br><span class="line">    <span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>;</span><br></pre></td></tr></table></figure><ul><li>向外部表中导入数据 </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &apos;/opt/module/datas/dept.txt&apos; into table default.dept;</span><br><span class="line">load data local inpath &apos;/opt/module/datas/emp.txt&apos; into table default.emp;</span><br></pre></td></tr></table></figure><p>查询结果<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> emp; </span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> dept;</span><br></pre></td></tr></table></figure></p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190324164442.png" alt=""><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190324164458.png" alt=""></p><ul><li>查看表格式化数据 </li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">desc formatted dept;</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190324164602.png" alt=""></p><h3 id="管理表与外部表的互相转换"><a href="#管理表与外部表的互相转换" class="headerlink" title="管理表与外部表的互相转换"></a>管理表与外部表的互相转换</h3><ul><li>修改内部表student2为外部表</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> student2 <span class="keyword">set</span> tblproperties(<span class="string">'EXTERNAL'</span>=<span class="string">'TRUE'</span>);</span><br></pre></td></tr></table></figure><ul><li>查询表的类型</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">desc formatted student2;</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190324170327.png" alt=""></p><ul><li>修改外部表student2为内部表</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> student2 <span class="keyword">set</span> tblproperties(<span class="string">'EXTERNAL'</span>=<span class="string">'FALSE'</span>);</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190324170439.png" alt=""></p><h3 id="分区表"><a href="#分区表" class="headerlink" title="分区表"></a>分区表</h3><p>分区表实际上就是对应一个 HDFS 文件系统上的独立的文件夹，该文件夹下是该分区<br>所有的数据文件。Hive 中的分区就是分目录，把一个大的数据集根据业务需要分割成小的<br>数据集。在查询时通过 WHERE 子句中的表达式选择查询所需要的指定的分区，这样的查<br>询效率会提高很多。<br>因为表是外部表，所以 Hive 并非认为其完全拥有这份数据。<strong>删除该表并不会删除掉这<br>份数据，不过描述表的元数据信息会被删除掉。</strong> </p><ul><li>创建分区表</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> dept_partition( </span><br><span class="line">deptno <span class="built_in">int</span>, </span><br><span class="line">dname <span class="keyword">string</span>, </span><br><span class="line">loc <span class="keyword">string</span> ) </span><br><span class="line">partitioned <span class="keyword">by</span> (<span class="keyword">month</span> <span class="keyword">string</span>) </span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>;</span><br></pre></td></tr></table></figure><ul><li>加载数据到分区表中 </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &apos;/opt/module/datas/dept.txt&apos; into table default.dept_partition partition(month=&apos;201809&apos;);</span><br><span class="line">load data local inpath &apos;/opt/module/datas/dept.txt&apos; into table default.dept_partition partition(month=&apos;201808&apos;);</span><br><span class="line">load data local inpath &apos;/opt/module/datas/dept.txt&apos; into table default.dept_partition partition(month=&apos;201807&apos;);</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190324172605.png" alt=""></p><ul><li>查询分区表中数据 </li></ul><p>单分区查询<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> dept_partition <span class="keyword">where</span> <span class="keyword">month</span>=<span class="string">'201809'</span>;</span><br></pre></td></tr></table></figure></p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190324175204.png" alt=""></p><p>多分区联合查询<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> dept_partition <span class="keyword">where</span> <span class="keyword">month</span>=<span class="string">'201809'</span></span><br><span class="line"><span class="keyword">union</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> dept_partition <span class="keyword">where</span> <span class="keyword">month</span>=<span class="string">'201808'</span></span><br><span class="line"><span class="keyword">union</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> dept_partition <span class="keyword">where</span> <span class="keyword">month</span>=<span class="string">'201807'</span>;</span><br></pre></td></tr></table></figure></p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190324180218.png" alt=""></p><ul><li>增加分区</li></ul><p>增加单个分区<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> dept_partition <span class="keyword">add</span> <span class="keyword">partition</span>(<span class="keyword">month</span>=<span class="string">'201806'</span>);</span><br></pre></td></tr></table></figure></p><p>增加多个分区<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> dept_partition <span class="keyword">add</span> <span class="keyword">partition</span>(<span class="keyword">month</span>=<span class="string">'201805'</span>) <span class="keyword">partition</span>(<span class="keyword">month</span>=<span class="string">'201804'</span>);</span><br></pre></td></tr></table></figure></p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190324181103.png" alt=""></p><ul><li>删除分区 </li></ul><p>删除单个分区<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> dept_partition <span class="keyword">drop</span> <span class="keyword">partition</span> (<span class="keyword">month</span>=<span class="string">'201804'</span>);</span><br></pre></td></tr></table></figure></p><p>同时删除多个分区<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> dept_partition <span class="keyword">drop</span> <span class="keyword">partition</span> (<span class="keyword">month</span>=<span class="string">'201805'</span>), <span class="keyword">partition</span> </span><br><span class="line">(<span class="keyword">month</span>=<span class="string">'201806'</span>);</span><br></pre></td></tr></table></figure></p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190324184116.png" alt=""><br><strong>这里需要注意的是删除多个分区是以” , “ 分割，而增加多个分区是以空格分割。</strong></p><ul><li>查看分区表有多少分区 </li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">partitions</span> dept_partition;</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190324184717.png" alt=""></p><ul><li>查看分区表结构 </li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">desc formatted dept_partition;</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190324184926.png" alt=""></p><h2 id="修改表"><a href="#修改表" class="headerlink" title="修改表"></a>修改表</h2><h3 id="重命名表"><a href="#重命名表" class="headerlink" title="重命名表"></a>重命名表</h3><p>语法：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">RENAME</span> <span class="keyword">TO</span> new_table_name</span><br></pre></td></tr></table></figure></p><h3 id="增加-修改-替换列信息"><a href="#增加-修改-替换列信息" class="headerlink" title="增加/修改/替换列信息"></a>增加/修改/替换列信息</h3><ul><li>语法</li></ul><p>更新列<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">CHANGE</span> [<span class="keyword">COLUMN</span>] col_old_name col_new_name column_type [<span class="keyword">COMMENT</span> col_comment] [<span class="keyword">FIRST</span>|<span class="keyword">AFTER</span> column_name]</span><br></pre></td></tr></table></figure></p><p>增加和替换列 </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">ADD</span>|<span class="keyword">REPLACE</span> <span class="keyword">COLUMNS</span> (col_name data_type [<span class="keyword">COMMENT</span> col_comment], ...)</span><br></pre></td></tr></table></figure><p><em>ADD 是代表新增一字段，字段位置在所有列后面(partition 列前)，REPLACE 则是<br>表示替换表中所有字段。</em></p><hr>]]></content>
    
    <summary type="html">
    
      这是大数据入门的第八篇文章
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Hive" scheme="http://yoursite.com/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>大数据入门07-Hive安装配置与用法</title>
    <link href="http://yoursite.com/2019/01/02/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A807-Hive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E4%B8%8E%E7%94%A8%E6%B3%95/"/>
    <id>http://yoursite.com/2019/01/02/大数据入门07-Hive安装配置与用法/</id>
    <published>2019-01-02T14:00:04.000Z</published>
    <updated>2019-04-14T10:16:11.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><p><img src="https://" alt="" style="width:100%"><br>在这篇文章中，我们会安装配置Hive,并且把Hive的元数据库配置在mysql上面。<br><a id="more"></a></p><h2 id="Hive安装配置"><a href="#Hive安装配置" class="headerlink" title="Hive安装配置"></a>Hive安装配置</h2><p>下载地址:<a href="https://mirrors.tuna.tsinghua.edu.cn/apache/hive/" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/apache/hive/</a></p><h3 id="下载-amp-安装"><a href="#下载-amp-安装" class="headerlink" title="下载&amp;安装"></a>下载&amp;安装</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/apache/hive/hive-2.3.4/apache-hive-2.3.4-bin.tar.gz</span><br></pre></td></tr></table></figure><p>解压到/opt/module/目录<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf tar -zxvf apache-hive-2.3.4-bin.tar.gz  -C ../module/hive-2.3.4</span><br></pre></td></tr></table></figure></p><h3 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br></pre></td></tr></table></figure><p>插入以下内容<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">##HIVE_HOME</span><br><span class="line">export HIVE_HOME=/opt/module/hive-2.3.4</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br></pre></td></tr></table></figure></p><p>刷新环境<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></p><h3 id="配置Hive"><a href="#配置Hive" class="headerlink" title="配置Hive"></a>配置Hive</h3><p>切换到Hive/conf目录中<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp hive-env.sh.template hive-env.sh</span><br></pre></td></tr></table></figure></p><p>在hive-env.sh文件中添加hadoop路径以及hive的conf路径<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HADOOP_HOME=/opt/module/hadoop-2.7.7</span><br><span class="line">export HIVE_CONF_DIR=/opt/module/hive-2.3.4</span><br></pre></td></tr></table></figure></p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190302224327.png" alt=""></p><h2 id="安装MySQL数据库"><a href="#安装MySQL数据库" class="headerlink" title="安装MySQL数据库"></a>安装MySQL数据库</h2><p>hive默认自带的derby数据库，但是在这种模式下，hive只能打开一个。所以我们把hive的元数据库搭建在MySQL上面</p><h3 id="下载安装"><a href="#下载安装" class="headerlink" title="下载安装"></a>下载安装</h3><ul><li>下载地址：<a href="https://dev.mysql.com/downloads/mysql/5.7.html#downloads" target="_blank" rel="noopener">https://dev.mysql.com/downloads/mysql/5.7.html#downloads</a><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190302224741.png" alt=""></li><li>首先卸载操作系统可能会自带的mariadb-libs<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y remove mariadb-libs</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190302224842.png" alt=""></p><p>解压mysql rpm-bundle tar包<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir mysql</span><br><span class="line">tar -xvf mysql-5.7.25-1.el7.x86_64.rpm-bundle.tar -C mysql</span><br></pre></td></tr></table></figure></p><ul><li>开始安装mysq<br>一定要按照下面的顺序来安装，否则会安装不成功：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh mysql-community-common-5.7.25-1.el7.x86_64.rpm</span><br><span class="line">rpm -ivh mysql-community-libs-5.7.25-1.el7.x86_64.rpm</span><br><span class="line">rpm -ivh mysql-community-client-5.7.25-1.el7.x86_64.rpm</span><br><span class="line">rpm -ivh mysql-community-server-5.7.25-1.el7.x86_64.rpm</span><br><span class="line">rpm -ivh mysql-community-libs-compat-5.7.25-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure></li></ul><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><ul><li><p>启动mysql服务,并且设置为开机启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl start mysqld</span><br><span class="line">systemctl enable mysqld</span><br></pre></td></tr></table></figure></li><li><p>查看root用户初始密码,并且登录MySQL</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grep password /var/log/mysqld.log</span><br><span class="line">mysql -uroot -p</span><br></pre></td></tr></table></figure></li><li><p>修改MySQL的密码长度以及安全性要求<br>因为MySQL有长度以及安全性的要求，所以需要对此作出修改</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set global validate_password_policy=0; </span><br><span class="line">set global validate_password_length=1;</span><br></pre></td></tr></table></figure></li><li><p>修改root密码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set password = password(&apos;123456&apos;);</span><br></pre></td></tr></table></figure></li><li><p>设置远程登录权限</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grant all privileges on *.* to &apos;root&apos;@&apos;%&apos; identified by &apos;12345678&apos;;</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure></li></ul><p>到这里MySQL就配置完成了。</p><h2 id="配置Hive的MySQL元数据库"><a href="#配置Hive的MySQL元数据库" class="headerlink" title="配置Hive的MySQL元数据库"></a>配置Hive的MySQL元数据库</h2><p>在hive/conf目录中新增hive-site.xml文件并且插入以下内容<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp hive-default.xml.template hive-site.xml</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;jdbc:mysql://hadoop101:3306/hive?createDatabaseIfNotExist=true&amp;amp;useSSL=false&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;root&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;Username to use against metastore database&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;123456&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;password to use against metastore database&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><h3 id="下载mysql-connector-java"><a href="#下载mysql-connector-java" class="headerlink" title="下载mysql-connector-java"></a>下载mysql-connector-java</h3><p>在 <a href="https://dev.mysql.com/downloads/connector/j/5.1.html" target="_blank" rel="noopener">https://dev.mysql.com/downloads/connector/j/5.1.html</a> 中下载mysql-connector-java，并且把该文件拉到../hive/lib目录中</p><h3 id="初始化元数据库"><a href="#初始化元数据库" class="headerlink" title="初始化元数据库"></a>初始化元数据库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">schematool -dbType mysql -initSchema</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190302230835.png" alt=""><br>在这里遇到一个比较坑的就是官方文档是在hive/bin目录执行上面的命令的，但我在执行这条命令之后就遇到这个报错：<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190302231100.png" alt=""><br>卡了好久，切换到hive/conf目录再执行这条命令居然成功了- - ，不知道是不是一个bug</p><h2 id="启动Hive"><a href="#启动Hive" class="headerlink" title="启动Hive"></a>启动Hive</h2><p>在启动hive之前需要先启动hadoop的dfs</p><h3 id="启动dfs"><a href="#启动dfs" class="headerlink" title="启动dfs"></a>启动dfs</h3><p>切换到hadoop的sbin目录<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-dfs.sh</span><br></pre></td></tr></table></figure></p><h3 id="启动Hive-1"><a href="#启动Hive-1" class="headerlink" title="启动Hive"></a>启动Hive</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190302231259.png" alt=""><br>一个简单的测试：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show databases;</span><br></pre></td></tr></table></figure></p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190302231340.png" alt=""></p><h2 id="Hive-常见属性配置"><a href="#Hive-常见属性配置" class="headerlink" title="Hive 常见属性配置"></a>Hive 常见属性配置</h2><h3 id="Hive-数据仓库位置配置"><a href="#Hive-数据仓库位置配置" class="headerlink" title="Hive 数据仓库位置配置"></a>Hive 数据仓库位置配置</h3><ul><li>Default 数据仓库的最原始位置是在 hdfs 上的：/user/hive/warehouse 路径下</li><li>在仓库目录下，没有对默认的数据库 default 创建文件夹。如果某张表属于 default数据库，直接在数据仓库目录下创建一个文件夹。</li><li>修改 default 数据仓库原始位置（将 hive-default.xml.template 如下配置信息拷贝到hive-site.xml 文件中）<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;/user/hive/warehouse&lt;/value&gt;</span><br><span class="line">&lt;description&gt;location of default database for the warehouse&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li></ul><h3 id="查询后信息显示配置"><a href="#查询后信息显示配置" class="headerlink" title="查询后信息显示配置"></a>查询后信息显示配置</h3><p>在 hive-site.xml 文件中添加如下配置信息，就可以实现显示当前数据库，以及查询表的头信息配置。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hive.cli.print.header&lt;/name&gt;</span><br><span class="line">&lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hive.cli.print.current.db&lt;/name&gt;</span><br><span class="line">&lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p><p>重新启动 hive，对比配置前后差异</p><ul><li><p>配置前：<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190319143023.png" alt=""></p></li><li><p>配置后：<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190319143119.png" alt=""></p></li></ul><h3 id="Hive-运行日志信息配置"><a href="#Hive-运行日志信息配置" class="headerlink" title="Hive 运行日志信息配置"></a>Hive 运行日志信息配置</h3><p>Hive 的 log 默认存放在/tmp/atguigu/hive.log 目录下（当前用户名下）<br>修改 hive 的 log 存放日志到/opt/module/hive/logs</p><ul><li>修改/opt/module/hive/conf/hive-log4j.properties.template 文件名称为hive-log4j.properties</li><li>在 hive-log4j.properties 文件中修改 log 存放位置<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.log.dir=/opt/module/hive/logs</span><br></pre></td></tr></table></figure></li></ul><p>到这里，Hive的安装配置就完成啦！</p><hr>]]></content>
    
    <summary type="html">
    
      这是大数据入门的第七篇文章
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Hive" scheme="http://yoursite.com/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>大数据入门06-spark项目实战</title>
    <link href="http://yoursite.com/2018/12/25/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A806-spark%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"/>
    <id>http://yoursite.com/2018/12/25/大数据入门06-spark项目实战/</id>
    <published>2018-12-25T08:57:49.000Z</published>
    <updated>2019-04-14T10:16:21.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><p><img src="https://" alt="" style="width:100%"><br>在这篇文章中，我们会用pyspark分析空气质量,并且把数据存入elasticsearch,用kibana进行可视化。<br><a id="more"></a></p><h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><p>数据来源：<a href="http://stateair.net/web/historical/1/1.html" target="_blank" rel="noopener">http://stateair.net/web/historical/1/1.html</a></p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190217170619.png" alt=""><br>我们把数据下载到本地，然后上传到hdfs</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put Beijing* /data</span><br></pre></td></tr></table></figure><h2 id="编写pyspark程序"><a href="#编写pyspark程序" class="headerlink" title="编写pyspark程序"></a>编写pyspark程序</h2><h3 id="创建sparkSession"><a href="#创建sparkSession" class="headerlink" title="创建sparkSession"></a>创建sparkSession</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark = SparkSession.builder.appName(<span class="string">"project"</span>).getOrCreate()</span><br></pre></td></tr></table></figure><h3 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data2017 = spark.read.format(<span class="string">"csv"</span>).option(<span class="string">"header"</span>,<span class="string">"true"</span>).option(<span class="string">"inferSchema"</span>,<span class="string">"true"</span>).load(<span class="string">"/data/Beijing_2017_HourlyPM25_created20170803.csv"</span>).select(<span class="string">"Year"</span>,<span class="string">"Month"</span>,<span class="string">"Day"</span>,<span class="string">"Hour"</span>,<span class="string">"Value"</span>,<span class="string">"QC Name"</span>)</span><br><span class="line">data2016 = spark.read.format(<span class="string">"csv"</span>).option(<span class="string">"header"</span>,<span class="string">"true"</span>).option(<span class="string">"inferSchema"</span>,<span class="string">"true"</span>).load(<span class="string">"/data/Beijing_2016_HourlyPM25_created20170201.csv"</span>).select(<span class="string">"Year"</span>,<span class="string">"Month"</span>,<span class="string">"Day"</span>,<span class="string">"Hour"</span>,<span class="string">"Value"</span>,<span class="string">"QC Name"</span>)</span><br><span class="line">data2015 = spark.read.format(<span class="string">"csv"</span>).option(<span class="string">"header"</span>,<span class="string">"true"</span>).option(<span class="string">"inferSchema"</span>,<span class="string">"true"</span>).load(<span class="string">"/data/Beijing_2015_HourlyPM25_created20160201.csv"</span>).select(<span class="string">"Year"</span>,<span class="string">"Month"</span>,<span class="string">"Day"</span>,<span class="string">"Hour"</span>,<span class="string">"Value"</span>,<span class="string">"QC Name"</span>)</span><br></pre></td></tr></table></figure><p>其中option(“inferSchema”,”true”)是用于自动推导数值类型的</p><h3 id="编写自定义函数"><a href="#编写自定义函数" class="headerlink" title="编写自定义函数"></a>编写自定义函数</h3><p>我们需要把value的值进行聚合，并且按照空气质量指数进行划分<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">0-50      健康</span><br><span class="line">51-100    中等</span><br><span class="line">101-150   对敏感人群不健康</span><br><span class="line">151-200   不健康</span><br><span class="line">201-300   非常不健康</span><br><span class="line">301-500   危险</span><br><span class="line">&gt;500      爆表</span><br></pre></td></tr></table></figure></p><ul><li>自定义函数的一般流程<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.创建普通的python函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">toDate</span><span class="params">(s)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> str(s)+<span class="string">'-'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.注册自定义函数</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> udf</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StringType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据python的返回值类型定义好spark对应的数据类型</span></span><br><span class="line"><span class="comment"># python函数中返回的是string，对应的pyspark是StringType</span></span><br><span class="line">toDateUDF=udf(toDate, StringType())  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用自定义函数</span></span><br><span class="line">df1.withColumn(<span class="string">'color'</span>,toDateUDF(<span class="string">'color'</span>)).show()</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_grade</span><span class="params">(value)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> value &lt;= <span class="number">50</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"健康"</span></span><br><span class="line">    <span class="keyword">elif</span> value &lt;= <span class="number">100</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"中等"</span></span><br><span class="line">    <span class="keyword">elif</span> value &lt;= <span class="number">150</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"对敏感人群不健康"</span></span><br><span class="line">    <span class="keyword">elif</span> value &lt;= <span class="number">200</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"不健康"</span></span><br><span class="line">    <span class="keyword">elif</span> value &lt;= <span class="number">300</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"非常不健康"</span></span><br><span class="line">    <span class="keyword">elif</span> value &lt;= <span class="number">500</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"危险"</span></span><br><span class="line">    <span class="keyword">elif</span> value &gt; <span class="number">500</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"爆表"</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">grade_function_udf = udf(get_grade, StringType())</span><br></pre></td></tr></table></figure><h3 id="按空气质量指数进行分组聚合"><a href="#按空气质量指数进行分组聚合" class="headerlink" title="按空气质量指数进行分组聚合"></a>按空气质量指数进行分组聚合</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">group2017 = data2017.withColumn(<span class="string">"Grade"</span>, grade_function_udf(data2017[<span class="string">'Value'</span>])).groupBy(<span class="string">"Grade"</span>).count()</span><br><span class="line">group2016 = data2016.withColumn(<span class="string">"Grade"</span>, grade_function_udf(data2016[<span class="string">'Value'</span>])).groupBy(<span class="string">"Grade"</span>).count()</span><br><span class="line">group2015 = data2015.withColumn(<span class="string">"Grade"</span>, grade_function_udf(data2015[<span class="string">'Value'</span>])).groupBy(<span class="string">"Grade"</span>).count()</span><br><span class="line"></span><br><span class="line">result2017 = group2017.select(<span class="string">"Grade"</span>, <span class="string">"count"</span>).withColumn(<span class="string">"precent"</span>,group2017[<span class="string">'count'</span>] / data2017.count()*<span class="number">100</span>)</span><br><span class="line">result2016 = group2016.select(<span class="string">"Grade"</span>, <span class="string">"count"</span>).withColumn(<span class="string">"precent"</span>,group2016[<span class="string">'count'</span>] / data2016.count()*<span class="number">100</span>)</span><br><span class="line">result2015 = group2015.select(<span class="string">"Grade"</span>, <span class="string">"count"</span>).withColumn(<span class="string">"precent"</span>,group2015[<span class="string">'count'</span>] / data2015.count()*<span class="number">100</span>)</span><br></pre></td></tr></table></figure><h3 id="数据写入到elasticsearch"><a href="#数据写入到elasticsearch" class="headerlink" title="数据写入到elasticsearch"></a>数据写入到elasticsearch</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">result2017.selectExpr(&quot;Grade as grade&quot;, &quot;count&quot;, &quot;precent&quot;).write.format(&quot;org.elasticsearch.spark.sql&quot;).option(&quot;es.nodes&quot;,&quot;192.168.111.101:9200&quot;).mode(&quot;overwrite&quot;).save(&quot;weather2017/pm&quot;)</span><br><span class="line">result2016.selectExpr(&quot;Grade as grade&quot;, &quot;count&quot;, &quot;precent&quot;).write.format(&quot;org.elasticsearch.spark.sql&quot;).option(&quot;es.nodes&quot;,&quot;192.168.111.101:9200&quot;).mode(&quot;overwrite&quot;).save(&quot;weather2016/pm&quot;)</span><br><span class="line">result2015.selectExpr(&quot;Grade as grade&quot;, &quot;count&quot;, &quot;precent&quot;).write.format(&quot;org.elasticsearch.spark.sql&quot;).option(&quot;es.nodes&quot;,&quot;192.168.111.101:9200&quot;).mode(&quot;overwrite&quot;).save(&quot;weather2015/pm&quot;)</span><br></pre></td></tr></table></figure><p>完整的代码在 <a href="https://github.com/dik111/pyspark-project/blob/master/13/wea.py" target="_blank" rel="noopener">https://github.com/dik111/pyspark-project/blob/master/13/wea.py</a></p><h2 id="Elasticsearch安装配置"><a href="#Elasticsearch安装配置" class="headerlink" title="Elasticsearch安装配置"></a>Elasticsearch安装配置</h2><p>下载地址：<a href="https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.6.0.tar.gz" target="_blank" rel="noopener">https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.6.0.tar.gz</a></p><h3 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf elasticsearch-6.6.0.tar.gz -C ../module/</span><br></pre></td></tr></table></figure><p>解压完成之后需要在elasticsearch目录中，修改配置文件/config/elasticsearch.yml<br>添加以下内容<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bootstrap.system_call_filter: false</span><br><span class="line">network.host: 0.0.0.0</span><br></pre></td></tr></table></figure></p><h3 id="启动elasticsearch"><a href="#启动elasticsearch" class="headerlink" title="启动elasticsearch"></a>启动elasticsearch</h3><p>在后台启动elasticsearch<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /bin</span><br><span class="line">nohup ./elasticsearch &amp;</span><br></pre></td></tr></table></figure></p><p>这里需要注意的是elasticsearch不能用root用户启动，所以要切换到非root用户启动。<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190217210745.png" alt=""></p><h2 id="Kibana安装配置"><a href="#Kibana安装配置" class="headerlink" title="Kibana安装配置"></a>Kibana安装配置</h2><p>下载地址：<a href="https://artifacts.elastic.co/downloads/kibana/kibana-6.6.0-linux-x86_64.tar.gz" target="_blank" rel="noopener">https://artifacts.elastic.co/downloads/kibana/kibana-6.6.0-linux-x86_64.tar.gz</a></p><h3 id="安装配置-1"><a href="#安装配置-1" class="headerlink" title="安装配置"></a>安装配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf kibana-6.6.0-linux-x86_64.tar.gz -C ../module/</span><br></pre></td></tr></table></figure><p>解压完成之后需要在kibana目录中，修改/config/kibana.yml 文件<br>添加以下内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">server.host: &quot;0.0.0.0&quot;</span><br><span class="line">elasticsearch.hosts: [&quot;http://hadoop101:9200&quot;]</span><br></pre></td></tr></table></figure></p><h3 id="启动kibana"><a href="#启动kibana" class="headerlink" title="启动kibana"></a>启动kibana</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd bin/</span><br><span class="line">nohup ./kibana &amp;</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190217212250.png" alt=""></p><h2 id="数据写入到elasticsearch-1"><a href="#数据写入到elasticsearch-1" class="headerlink" title="数据写入到elasticsearch"></a>数据写入到elasticsearch</h2><h3 id="下载elasticsearch-spark-jar包"><a href="#下载elasticsearch-spark-jar包" class="headerlink" title="下载elasticsearch-spark jar包"></a>下载elasticsearch-spark jar包</h3><p>下载地址：<a href="https://www.elastic.co/downloads/hadoop" target="_blank" rel="noopener">https://www.elastic.co/downloads/hadoop</a></p><h3 id="写入数据"><a href="#写入数据" class="headerlink" title="写入数据"></a>写入数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/module/spark-2.3.2-bin-hadoop2.7/bin/</span><br><span class="line">./spark-submit --master yarn /home/dik/python-project/13/wea.py --jars /opt/module/elasticsearch-hadoop-6.6.0/dist/elasticsearch-spark-20_2.11-6.6.0.jar</span><br></pre></td></tr></table></figure><p>如果提示：ClassNotFoundException Failed to find data source: org.elasticsearch.spark.sql.，则表示spark没有发现jar包，此时需重新编译pyspark：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/module/spark-2.3.2-bin-hadoop2.7/python</span><br><span class="line">python setup.py sdist </span><br><span class="line">pip install dist/*.tar.gz</span><br></pre></td></tr></table></figure></p><h2 id="Kibana可视化"><a href="#Kibana可视化" class="headerlink" title="Kibana可视化"></a>Kibana可视化</h2><ul><li><p>打开Mangement中的Index patterns<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190217221214.png" alt=""></p></li><li><p>创建新的index pattern<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190217221359.png" alt=""></p></li><li><p>然后在visualize中创建可视化条形图<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190217221555.png" alt=""></p></li><li>Y轴：<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190217221623.png" alt=""></li><li>X轴：<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190217221711.png" alt=""></li><li><p>Split Series：<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190217221743.png" alt=""></p></li><li><p>Metrics：<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190217221930.png" alt=""></p></li><li><p>最终完成效果：<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190217221945.png" alt=""></p><hr></li></ul>]]></content>
    
    <summary type="html">
    
      这是大数据入门的第六篇文章
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="pyspark" scheme="http://yoursite.com/tags/pyspark/"/>
    
  </entry>
  
  <entry>
    <title>大数据入门05-spark运行模式</title>
    <link href="http://yoursite.com/2018/12/21/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A805-spark%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/"/>
    <id>http://yoursite.com/2018/12/21/大数据入门05-spark运行模式/</id>
    <published>2018-12-21T05:38:29.000Z</published>
    <updated>2019-02-17T08:40:33.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><p><img src="https://" alt="" style="width:100%"></p><a id="more"></a><h2 id="本地模式"><a href="#本地模式" class="headerlink" title="本地模式"></a>本地模式</h2><p>本地模式是我们在IDE上面编写完程序，然后运行的一种模式。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit \</span><br><span class="line">  --class &lt;main-class&gt; \</span><br><span class="line">  --master &lt;master-url&gt; \</span><br><span class="line">  --deploy-mode &lt;deploy-mode&gt; \</span><br><span class="line">  --conf &lt;key&gt;=&lt;value&gt; \</span><br><span class="line">  ... # other options</span><br><span class="line">  &lt;application-jar&gt; \</span><br><span class="line">  [application-arguments]</span><br></pre></td></tr></table></figure></p><h3 id="常用的-options"><a href="#常用的-options" class="headerlink" title="常用的 options :"></a>常用的 options :</h3><ul><li>—class: 您的应用程序的入口点（例如。 org.apache.spark.examples.SparkPi)</li><li>—master: 集群的 master URL (例如 spark://23.195.26.187:7077)</li><li>—deploy-mode: 是在 worker 节点(cluster) 上还是在本地作为一个外部的客户端(client) 部署您的 driver(默认: client) †</li><li>—conf: 按照 key=value 格式任意的 Spark 配置属性。对于包含空格的 value（值）使用引号包 “key=value” 起来。</li><li>application-jar: 包括您的应用以及所有依赖的一个打包的 Jar 的路径。该 URL 在您的集群上必须是全局可见的，例如，一个 hdfs:// path 或者一个 file:// 在所有节点是可见的。（对于 Python 应用，在 &lt;application-jar&gt; 的位置简单的传递一个 .py 文件而不是一个 JAR，并且可以用 —py-files 添加 Python .zip，.egg 或者 .py 文件到 search path（搜索路径））</li><li>application-arguments: 传递到您的 main class 的 main 方法的参数，如果有的话。</li></ul><h3 id="简单例子"><a href="#简单例子" class="headerlink" title="简单例子"></a>简单例子</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./spark-submit --master local[2] --name spark-local /home/dik/python-project/03/spark0301.py</span><br></pre></td></tr></table></figure><h2 id="Spark-on-yarn模式"><a href="#Spark-on-yarn模式" class="headerlink" title="Spark on yarn模式"></a>Spark on yarn模式</h2><p>spark on yarn模式是我们工作中用的比较多的一种模式，其用法其实跟本地模式是比较类似的。spark作为客户端而已，他需要做的事情就是提交作业到yarn上去执行</p><h3 id="配置spark-on-yarn"><a href="#配置spark-on-yarn" class="headerlink" title="配置spark on yarn"></a>配置spark on yarn</h3><ul><li>配置HADOOP_CONF_DIR 或者 YARN_CONF_DIR</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /spark-2.3.2-bin-hadoop2.7/conf/spark-env.sh</span><br></pre></td></tr></table></figure><p>添加<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HADOOP_CONF_DIR=/opt/module/hadoop-2.7.7/etc/hadoop</span><br></pre></td></tr></table></figure></p><h3 id="简单例子-1"><a href="#简单例子-1" class="headerlink" title="简单例子"></a>简单例子</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./spark-submit --master yarn --name spark-local /home/dik/python-project/03/spark0301.py</span><br></pre></td></tr></table></figure><h3 id="deploy-mode"><a href="#deploy-mode" class="headerlink" title="deploy mode"></a>deploy mode</h3><p>yarn支持client和cluster模式：driver运行在哪里</p><ul><li>client：提交作业的进程是不能停止的，否则作业就挂了</li><li>cluster：提交完作业，那么提交作业端就可以断开了，因为driver是运行在am里面的</li></ul><h2 id="开启历史日志监控"><a href="#开启历史日志监控" class="headerlink" title="开启历史日志监控"></a>开启历史日志监控</h2><p>spark的作业如果正在运行的话，我们可以在4040端口上面看，但是如果作业结束的话，我们便无法查看了。因此我们需要建立一个历史日志监控的系统。</p><ul><li><p>在/spark-2.3.2-bin-hadoop2.7/conf目录中创建spark-defaults.conf文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp spark-defaults.conf.template spark-defaults.conf</span><br></pre></td></tr></table></figure></li><li><p>在当前安装Spark的节点上，进入到conf目录，在配置文件spark-defaults.conf添加下面的配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark.eventLog.enabled  true    # 开启日志记录</span><br><span class="line">spark.eventLog.dir      hdfs://hadoop101:9000/directory   # 日志的保存位置</span><br></pre></td></tr></table></figure></li><li><p>配置spark-env.sh 文件<br>添加</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SPARK_HISTORY_OPTS=&quot;-Dspark.history.fs.logDirectory=hdfs://hadoop101:9000/directory&quot;</span><br></pre></td></tr></table></figure></li><li><p>在/sbin目录下启动历史日志</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-history-server.sh</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190217163726.png" alt=""><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190217163819.png" alt=""></p><hr>]]></content>
    
    <summary type="html">
    
      这是大数据入门的第五篇文章
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="pyspark" scheme="http://yoursite.com/tags/pyspark/"/>
    
  </entry>
  
  <entry>
    <title>大数据入门04-pyspark环境搭建</title>
    <link href="http://yoursite.com/2018/12/19/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A804-spark%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <id>http://yoursite.com/2018/12/19/大数据入门04-spark环境搭建/</id>
    <published>2018-12-19T13:38:55.000Z</published>
    <updated>2019-02-16T08:32:40.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><p><img src="https://" alt="" style="width:100%"></p><a id="more"></a><h2 id="安装Spark依赖的Scala"><a href="#安装Spark依赖的Scala" class="headerlink" title="安装Spark依赖的Scala"></a>安装Spark依赖的Scala</h2><p>Hadoop的安装请参考上面提到的博文，因为Spark依赖scala，所以在安装Spark之前，这里要先安装scala。在每个节点上都进行安装。</p><h3 id="下载和解压缩Scala"><a href="#下载和解压缩Scala" class="headerlink" title="下载和解压缩Scala"></a>下载和解压缩Scala</h3><p>打开地址：<a href="https://www.scala-lang.org/download/" target="_blank" rel="noopener">https://www.scala-lang.org/download/</a></p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190131141743.png" alt=""></p><h3 id="配置scala环境变量"><a href="#配置scala环境变量" class="headerlink" title="配置scala环境变量"></a>配置scala环境变量</h3><ul><li>打开配置文件<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export SCALA_HOME=/root/module/scala-2.12.8</span><br><span class="line">export PATH=$PATH:$SCALA_HOME/bin</span><br></pre></td></tr></table></figure><ul><li><p>保存之后刷新配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></li><li><p>验证是否配置好</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scala -version</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190131142644.png" alt=""></p><h2 id="下载和解压缩Spark"><a href="#下载和解压缩Spark" class="headerlink" title="下载和解压缩Spark"></a>下载和解压缩Spark</h2><p>打开下载地址：<br><a href="http://spark.apache.org/downloads.html" target="_blank" rel="noopener">http://spark.apache.org/downloads.html</a></p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190131142831.png" alt=""></p><p>选择清华源</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190131142859.png" alt=""></p><h3 id="配置spark环境变量"><a href="#配置spark环境变量" class="headerlink" title="配置spark环境变量"></a>配置spark环境变量</h3><ul><li>编辑/etc/profile文件，添加</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export SPARK_HOME=/root/module/spark-2.3.2-bin-hadoop2.7</span><br><span class="line">export PATH=$PATH:$SPARK_HOME/bin</span><br><span class="line">export PYSPARK_PYTHON=/home/dik/anaconda3/bin/python3.7</span><br></pre></td></tr></table></figure><h3 id="配置conf目录下的文件"><a href="#配置conf目录下的文件" class="headerlink" title="配置conf目录下的文件"></a>配置conf目录下的文件</h3><p>/root/module/spark-2.3.2-bin-hadoop2.7/conf目录下的文件进行配置</p><ul><li>新建spark-env.h文件<br>以spark为我们创建好的模板创建一个spark-env.h文件，命令是：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp    spark-env.sh.template   spark-env.sh</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190131143625.png" alt=""></p><ul><li>编辑spark-env.h文件，在里面加入配置(具体路径以自己的为准)：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export SCALA_HOME=/root/module/scala-2.12.8</span><br><span class="line">export JAVA_HOME=/root/module/jdk1.8.0_191</span><br><span class="line">export HADOOP_HOME=/root/module/hadoop-2.7.7</span><br><span class="line">export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop</span><br><span class="line">export SPARK_HOME=/root/module/spark-2.3.2-bin-hadoop2.7</span><br></pre></td></tr></table></figure><h3 id="新建slaves文件"><a href="#新建slaves文件" class="headerlink" title="新建slaves文件"></a>新建slaves文件</h3><p>/root/module/spark-2.3.2-bin-hadoop2.7/conf目录下的文件进行配置</p><p>以spark为我们创建好的模板创建一个slaves文件，命令是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp    slaves.template   slaves</span><br></pre></td></tr></table></figure></p><p>编辑slaves文件，里面的内容为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark001</span><br></pre></td></tr></table></figure></p><h2 id="启动和测试Spark集群"><a href="#启动和测试Spark集群" class="headerlink" title="启动和测试Spark集群"></a>启动和测试Spark集群</h2><h3 id="启动Spark"><a href="#启动Spark" class="headerlink" title="启动Spark"></a>启动Spark</h3><ul><li><p>切换到sbin目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/module/spark-2.3.2-bin-hadoop2.7/sbin</span><br></pre></td></tr></table></figure></li><li><p>执行启动脚本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-all.sh</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190131145420.png" alt=""></p><ul><li>查看是否启动<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190131145519.png" alt=""></p><h3 id="测试和使用Spark集群"><a href="#测试和使用Spark集群" class="headerlink" title="测试和使用Spark集群"></a>测试和使用Spark集群</h3><ul><li><p>访问Spark集群提供的URL<br><a href="http://spark001:8080/" target="_blank" rel="noopener">http://spark001:8080/</a><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190131145627.png" alt=""></p></li><li><p>运行Spark提供的计算圆周率的示例程序<br>进入到Spark的根目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd ..</span><br></pre></td></tr></table></figure></li></ul><p>调用Spark自带的计算圆周率的Demo，执行下面的命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit --class org.apache.spark.examples.SparkPi --master local examples/jars/spark-examples_2.11-2.3.2.jar</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190131150149.png" alt=""></p><h2 id="配置pyspark远程调试环境"><a href="#配置pyspark远程调试环境" class="headerlink" title="配置pyspark远程调试环境"></a>配置pyspark远程调试环境</h2><h3 id="安装Anaconda3"><a href="#安装Anaconda3" class="headerlink" title="安装Anaconda3"></a>安装Anaconda3</h3><p>因为服务器自带的python版本是python2的，所以要安装python3,而Anaconda3是一个比较好的选择。</p><ul><li><p>下载地址：<br><a href="https://repo.continuum.io/archive/Anaconda3-5.1.0-Linux-x86_64.sh" target="_blank" rel="noopener">https://repo.continuum.io/archive/Anaconda3-5.1.0-Linux-x86_64.sh</a></p></li><li><p>依赖安装bzip2： yum -y install bzip2</p></li><li>安装anaconda3<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash Anaconda3-5.0.1-Linux-x86_64.sh</span><br></pre></td></tr></table></figure></li></ul><p>安装的过程比较简单，这里就不复述了。<br>安装完成之后刷新配置文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure></p><h3 id="配置本地pycharm环境"><a href="#配置本地pycharm环境" class="headerlink" title="配置本地pycharm环境"></a>配置本地pycharm环境</h3><ul><li>安装py4j</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install py4j</span><br></pre></td></tr></table></figure><ul><li>配置pycharm 远程</li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190131153852.png" alt=""><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190131153930.png" alt=""><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190131153955.png" alt=""></p><ul><li>配置远程的编译器</li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190131154157.png" alt=""></p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190131154416.png" alt=""></p><ul><li><p>新建一个pyspark项目<br>填入以下测试代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_map</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    map(func)</span></span><br><span class="line"><span class="string">将func函数作用到数据集的每一个元素上，生成一个新的分布式的数据集返回</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">word =&gt; (word,1)</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    data = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">    rdd1 = sc.parallelize(data)</span><br><span class="line">    rdd2 = rdd1.map(<span class="keyword">lambda</span> x: x * <span class="number">2</span>)</span><br><span class="line">    print(rdd2.collect())</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">'local[2]'</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    my_map()</span><br><span class="line"></span><br><span class="line">    sc.stop()</span><br></pre></td></tr></table></figure></li><li><p>配置<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190131154635.png" alt=""></p></li></ul><p>在里面加入对应的JAVA_HOME,PYTHONPATH,SPARK_HOME<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190131154819.png" alt=""></p><ul><li>运行代码<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190131154928.png" alt=""><br>如果没报错的话，那么就搭建成功了！<hr></li></ul>]]></content>
    
    <summary type="html">
    
      这是大数据入门的第四篇文章
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="pyspark" scheme="http://yoursite.com/tags/pyspark/"/>
    
  </entry>
  
  <entry>
    <title>大数据入门03-Hadoop完全分布式运行模式</title>
    <link href="http://yoursite.com/2018/12/18/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A803-Hadoop%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/"/>
    <id>http://yoursite.com/2018/12/18/大数据入门03-Hadoop完全分布式运行模式/</id>
    <published>2018-12-18T08:13:37.000Z</published>
    <updated>2019-02-17T05:32:17.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><p><img src="https://" alt="" style="width:100%"></p><a id="more"></a><h2 id="虚拟机准备"><a href="#虚拟机准备" class="headerlink" title="虚拟机准备"></a>虚拟机准备</h2><p>修改克隆主机的IP地址以及名字</p><ul><li>我们打开克隆的3台centos7虚拟机，修改里面对应的IP地址为105,106，107<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/sysconfig/network-scripts/ifcfg-eth0</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204162411.png" alt=""><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204162449.png" alt=""><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204162509.png" alt=""></p><ul><li><p>修改MAC地址<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190217133024.png" alt=""><br>在配置IP地址的文件中添加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MACADDR=XXXXXXXXXXXXXXXX</span><br></pre></td></tr></table></figure></li><li><p>修改主机的名字，分别为105,106,107</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/sysconfig/network</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204162841.png" alt=""><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204162858.png" alt=""><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204162911.png" alt=""></p><ul><li><p>修改hosts配置文件，添加对应的105，106，107的IP地址<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204170226.png" alt=""></p></li><li><p>为三台虚拟机配置ssh<br>分别在105，106，107上面创建ssh</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure></li></ul><p>然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）<br>进入到.ssh文件夹，将产生的公钥拷贝到目标机器上<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id hadoop105</span><br><span class="line">ssh-copy-id hadoop106</span><br><span class="line">ssh-copy-id hadoop107</span><br></pre></td></tr></table></figure></p><ul><li>编写xsync集群分发脚本<br>在~/bin目录在创建xsync创建文件，文件内容如下：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">touch xsync</span><br><span class="line">vim xsync</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">#1 获取输入参数个数，如果没有参数，直接退出</span><br><span class="line">pcount=$#</span><br><span class="line">if((pcount==0)); then</span><br><span class="line">echo no args;</span><br><span class="line">exit;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">#2 获取文件名称</span><br><span class="line">p1=$1</span><br><span class="line">fname=`basename $p1`</span><br><span class="line">echo fname=$fname</span><br><span class="line"></span><br><span class="line">#3 获取上级目录到绝对路径</span><br><span class="line">pdir=`cd -P $(dirname $p1); pwd`</span><br><span class="line">echo pdir=$pdir</span><br><span class="line"></span><br><span class="line">#4 获取当前用户名称</span><br><span class="line">user=`whoami`</span><br><span class="line"></span><br><span class="line">#5 循环</span><br><span class="line">for((host=103; host&lt;105; host++)); do</span><br><span class="line">        echo ------------------- hadoop$host --------------</span><br><span class="line">        rsync -rvl $pdir/$fname $user@hadoop$host:$pdir</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>其中#5 循环部分可以改成对应的主机名称<br>修改脚本 xsync 具有执行权限<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 777 xsync</span><br></pre></td></tr></table></figure></p><h2 id="集群配置"><a href="#集群配置" class="headerlink" title="集群配置"></a>集群配置</h2><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204212905.png" alt=""></p><ul><li>核心配置文件<br>配置core-site.xml<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop105 ~]# cd /opt/module/hadoop-2.7.7/etc/hadoop/</span><br><span class="line">[root@hadoop105 hadoop]# vim core-site.xml</span><br></pre></td></tr></table></figure></li></ul><p>把namenode节点改成105</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204213451.png" alt=""></p><ul><li>HDFS配置文件</li></ul><p>配置hadoop-env.sh</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop105 hadoop]# vim hadoop-env.sh</span><br><span class="line">export JAVA_HOME=/opt/module/jdk-11.0.1</span><br></pre></td></tr></table></figure><p>配置hdfs-site.xml<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop105 hadoop]# vim hdfs-site.xml</span><br></pre></td></tr></table></figure></p><p>在该文件中编写如下配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;hadoop107:50090&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p><ul><li>YARN配置文件<br>配置yarn-env.sh  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop105 hadoop]# vim yarn-env.sh</span><br><span class="line">export JAVA_HOME=/opt/module/jdk-11.0.1</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204215103.png" alt=""><br>配置yarn-site.xml<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- Reducer获取数据的方式 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">&lt;value&gt;hadoop106&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p><ul><li>MapReduce配置文件<br>配置mapred-env.sh<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop105 hadoop]# vim mapred-env.sh</span><br><span class="line">export JAVA_HOME=/opt/module/jdk-11.0.1</span><br></pre></td></tr></table></figure></li></ul><p>配置mapred-site.xml<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop105 hadoop]# cp mapred-site.xml.template mapred-site.xml</span><br><span class="line">[root@hadoop105 hadoop]# vim mapred-site.xml</span><br><span class="line"></span><br><span class="line">&lt;!-- 指定MR运行在Yarn上 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">&lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p><p>接着用xsync脚本把编写的文件同步到106,107<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync /opt/module/hadoop-2.7.7/etc/hadoop/</span><br></pre></td></tr></table></figure></p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204221353.png" alt=""></p><h2 id="群起集群"><a href="#群起集群" class="headerlink" title="群起集群"></a>群起集群</h2><ul><li><p>格式化NameNode<br>格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再分别在105,106,107上删除data和log数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rm -rf data/ logs/</span><br><span class="line">bin/hdfs namenode -format</span><br></pre></td></tr></table></figure></li><li><p>配置slaves</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop105 hadoop-2.7.7]# vim etc/hadoop/slaves</span><br><span class="line">hadoop105</span><br><span class="line">hadoop106</span><br><span class="line">hadoop107</span><br></pre></td></tr></table></figure></li></ul><p>接着把它分发到106，107<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~/bin/xsync /opt/module/hadoop-2.7.7/etc/hadoop/slaves</span><br></pre></td></tr></table></figure></p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204223134.png" alt=""></p><ul><li>启动HDFS<br>在hadoop105上启动：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-dfs.sh</span><br><span class="line">#sbin/stop-dfs.sh (关闭)</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204223740.png" alt=""><br>分别在105，106，107上面用jps命令查看是否启动正确：<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204223834.png" alt=""><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204223854.png" alt=""><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204223908.png" alt=""></p><ul><li>启动YARN<br>在hadoop106上启动：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-yarn.sh </span><br><span class="line">#sbin/stop-yarn.sh (关闭)</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204224224.png" alt=""><br>启动之后再在105，106，107上面用jps命令查看是否启动正确：<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204224259.png" alt=""><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204224320.png" alt=""><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204224334.png" alt=""><br>最后我们登录 <a href="http://hadoop105:50070/explorer.html#/" target="_blank" rel="noopener">http://hadoop105:50070/explorer.html#/</a><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204224454.png" alt=""><br>如果能成功打开，那么我们完全分布式集群就搭建成功了！</p><h2 id="集群基本测试"><a href="#集群基本测试" class="headerlink" title="集群基本测试"></a>集群基本测试</h2><p>我们上传一个小文件到集群上面用作测试:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs -put README.txt /</span><br></pre></td></tr></table></figure></p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204225130.png" alt=""><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190204225221.png" alt=""></p><hr>]]></content>
    
    <summary type="html">
    
      这是大数据入门的第三篇文章
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>大数据入门02-Hadoop伪分布式运行模式</title>
    <link href="http://yoursite.com/2018/12/17/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A802-Hadoop%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/"/>
    <id>http://yoursite.com/2018/12/17/大数据入门02-Hadoop伪分布式运行模式/</id>
    <published>2018-12-17T13:29:27.000Z</published>
    <updated>2018-12-23T07:10:33.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><p><img src="https://" alt="" style="width:100%"></p><a id="more"></a><h2 id="启动HDFS并运行MapReduce程序"><a href="#启动HDFS并运行MapReduce程序" class="headerlink" title="启动HDFS并运行MapReduce程序"></a>启动HDFS并运行MapReduce程序</h2><h3 id="执行步骤"><a href="#执行步骤" class="headerlink" title="执行步骤"></a>执行步骤</h3><ul><li>配置：hadoop-env.sh<br>Linux系统中获取JDK的安装路径,并且修改hadoop-env.sh文件中的JAVA_HOME：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $JAVA_HOME</span><br><span class="line">vim /opt/module/hadoop-2.7.7/etc/hadoop/hadoop-env.sh</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20181217215536.png" alt=""></p><ul><li>配置：core-site.xml<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /opt/module/hadoop-2.7.7/etc/hadoop/core-site.xml</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hdfs://hadoop100:9000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;/opt/module/hadoop-2.7.7/data/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20181217220516.png" alt=""></p><ul><li>配置：hdfs-site.xml<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /opt/module/hadoop-2.7.7/etc/hadoop/hdfs-site.xml</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定HDFS副本的数量 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">&lt;value&gt;1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20181217220409.png" alt=""></p><p>这里因为是伪分布式模式，所以副本的数量设置为1。</p><h3 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h3><ul><li>格式化NameNode（第一次启动时格式化，以后就不要总格式化）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/module/hadoop-2.7.7/</span><br><span class="line">bin/hdfs namenode -format</span><br></pre></td></tr></table></figure><ul><li><p>启动NameNode</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure></li><li><p>启动DataNode</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure></li></ul><h3 id="查看集群"><a href="#查看集群" class="headerlink" title="查看集群"></a>查看集群</h3><ul><li><p>查看是否启动成功<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20181217221822.png" alt=""></p></li><li><p>web端查看HDFS文件系统</p></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20181217222111.png" alt=""></p><p>注意：如果不能查看，看如下帖子处理<br><a href="http://www.cnblogs.com/zlslch/p/6604189.html" target="_blank" rel="noopener">http://www.cnblogs.com/zlslch/p/6604189.html</a></p><ul><li>查看产生的Log日志<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/module/hadoop-2.7.7/logs/</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20181217222402.png" alt=""></p><p>在企业中遇到Bug时，经常根据日志提示信息去分析问题、解决Bug。</p><h3 id="操作集群"><a href="#操作集群" class="headerlink" title="操作集群"></a>操作集群</h3><ul><li>在HDFS文件系统上创建一个input文件夹</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs -mkdir -p /user/dik/input</span><br></pre></td></tr></table></figure><ul><li>将测试文件内容上传到文件系统上</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs -put wcinput/wc.input</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20181223142636.png" alt=""></p><ul><li>运行MapReduce程序</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar  wordcount /user/dik/input   /user/dik/output</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20181223143354.png" alt=""></p><h2 id="启动YARN并运行MapReduce程序"><a href="#启动YARN并运行MapReduce程序" class="headerlink" title="启动YARN并运行MapReduce程序"></a>启动YARN并运行MapReduce程序</h2><h3 id="执行步骤-1"><a href="#执行步骤-1" class="headerlink" title="执行步骤"></a>执行步骤</h3><ul><li>配置yarn-env.sh</li></ul><p>配置一下JAVA_HOME</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">echo $JAVA_HOME</span><br><span class="line">vim /opt/module/hadoop-2.7.7/etc/hadoop/hadoop-env.sh</span><br><span class="line">export JAVA_HOME=/opt/module/jdk-11.0.1</span><br></pre></td></tr></table></figure><ul><li>配置yarn-site.xml</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /opt/module/hadoop-2.7.7/etc/hadoop/yarn-site.xml</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- Reducer获取数据的方式 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">                &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">&lt;value&gt;hadoop101&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">                &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 日志聚集功能使能 --&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line"></span><br><span class="line">                &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;604800&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br></pre></td></tr></table></figure><ul><li>配置：mapred-env.sh</li></ul><p>配置一下JAVA_HOME</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim /opt/module/hadoop-2.7.7/etc/hadoop/mapred-env.sh</span><br><span class="line">export JAVA_HOME=/opt/module/jdk-11.0.1</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20181223145451.png" alt=""></p><ul><li>配置： (对mapred-site.xml.template重新命名为) mapred-site.xml</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mv mapred-site.xml.template mapred-site.xml</span><br><span class="line">vim /opt/module/hadoop-2.7.7/etc/hadoop/</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定MR运行在YARN上 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">                &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 历史服务器端地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class="line">&lt;value&gt;hadoop101:10020&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- 历史服务器web端地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hadoop101:19888&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><h3 id="启动集群-1"><a href="#启动集群-1" class="headerlink" title="启动集群"></a>启动集群</h3><p>启动前必须保证NameNode和DataNode已经启动</p><ul><li>启动ResourceManager</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/yarn-daemon.sh start resourcemanager</span><br></pre></td></tr></table></figure><ul><li>启动NodeManager</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/yarn-daemon.sh start nodemanager</span><br></pre></td></tr></table></figure><h3 id="集群操作"><a href="#集群操作" class="headerlink" title="集群操作"></a>集群操作</h3><ul><li>YARN的浏览器页面查看</li></ul><p><a href="http://hadoop101:8088/cluster" target="_blank" rel="noopener">http://hadoop101:8088/cluster</a></p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20181223150126.png" alt=""></p><ul><li>删除文件系统上的output文件</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs -rm -R /user/dik/outpu</span><br></pre></td></tr></table></figure><ul><li>执行MapReduce程序</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar  wordcount /user/dik/input /user/dik/output</span><br></pre></td></tr></table></figure><p>到这里一个简单的伪分布式运行模式就搭建成功啦！</p><hr>]]></content>
    
    <summary type="html">
    
      这是大数据入门的第二篇文章
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>大数据入门01-Hadoop运行环境搭建</title>
    <link href="http://yoursite.com/2018/12/09/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A801-Hadoop%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <id>http://yoursite.com/2018/12/09/大数据入门01-Hadoop运行环境搭建/</id>
    <published>2018-12-09T04:35:44.000Z</published>
    <updated>2018-12-09T11:03:48.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><p><img src="https://" alt="" style="width:100%"><br>这篇文章主要介绍的是Hadoop运行环境搭建<br><a id="more"></a></p><h2 id="虚拟机环境准备"><a href="#虚拟机环境准备" class="headerlink" title="虚拟机环境准备"></a>虚拟机环境准备</h2><h3 id="克隆虚拟机"><a href="#克隆虚拟机" class="headerlink" title="克隆虚拟机"></a>克隆虚拟机</h3><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20181209151821.png" alt=""></p><h3 id="修改克隆虚拟机的静态IP"><a href="#修改克隆虚拟机的静态IP" class="headerlink" title="修改克隆虚拟机的静态IP"></a>修改克隆虚拟机的静态IP</h3><p>进入 /etc/sysconfig/network-scripts中<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/sysconfig/network-scripts</span><br><span class="line">vim ifcfg-eth0</span><br></pre></td></tr></table></figure></p><p>需要对这几项进行修改：<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20181209152921.png" alt=""></p><h3 id="修改主机名"><a href="#修改主机名" class="headerlink" title="修改主机名"></a>修改主机名</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/sysconfig</span><br><span class="line">sudo vim network</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20181209153740.png" alt=""></p><h3 id="配置hosts文件"><a href="#配置hosts文件" class="headerlink" title="配置hosts文件"></a>配置hosts文件</h3><ul><li><p>打开hosts文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/hosts</span><br></pre></td></tr></table></figure></li><li><p>配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">192.168.111.100 hadoop100</span><br><span class="line">192.168.111.101 hadoop101</span><br><span class="line">192.168.111.102 hadoop102</span><br><span class="line">192.168.111.103 hadoop103</span><br><span class="line">192.168.111.104 hadoop104</span><br><span class="line">192.168.111.105 hadoop105</span><br><span class="line">192.168.111.106 hadoop106</span><br></pre></td></tr></table></figure></li></ul><h3 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld.service</span><br></pre></td></tr></table></figure><p>禁止防火墙开机启动<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl disable firewalld.service</span><br></pre></td></tr></table></figure></p><h3 id="在-opt目录下创建文件夹"><a href="#在-opt目录下创建文件夹" class="headerlink" title="在/opt目录下创建文件夹"></a>在/opt目录下创建文件夹</h3><ul><li><p>在/opt目录下创建module、software文件夹,其中software文件夹用于软件包的存储，module文件夹用于软件的安装</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir module</span><br><span class="line">sudo mkdir software</span><br></pre></td></tr></table></figure></li><li><p>修改module、software文件夹的所有者</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo chown dik:dik module/ software/</span><br></pre></td></tr></table></figure></li></ul><h2 id="安装JDK以及配置环境变量"><a href="#安装JDK以及配置环境变量" class="headerlink" title="安装JDK以及配置环境变量"></a>安装JDK以及配置环境变量</h2><h3 id="卸载现有JDK"><a href="#卸载现有JDK" class="headerlink" title="卸载现有JDK"></a>卸载现有JDK</h3><ul><li><p>查询是否安装Java软件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa | grep java</span><br></pre></td></tr></table></figure></li><li><p>用Xshell工具将JDK导入到opt目录下面的software文件夹下面</p></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20181209174120.png" alt=""></p><ul><li>在Linux系统下的opt目录中查看软件包是否导入成功</li></ul><h3 id="解压JDK到-opt-module目录下"><a href="#解压JDK到-opt-module目录下" class="headerlink" title="解压JDK到/opt/module目录下"></a>解压JDK到/opt/module目录下</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf jdk-11.0.1_linux-x64_bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure><h3 id="配置JDK环境变量"><a href="#配置JDK环境变量" class="headerlink" title="配置JDK环境变量"></a>配置JDK环境变量</h3><ul><li><p>先获取JDK路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[dik@hadoop102 jdk-11.0.1]$ pwd</span><br><span class="line">/opt/module/jdk-11.0.1</span><br></pre></td></tr></table></figure></li><li><p>打开/etc/profile文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br></pre></td></tr></table></figure></li><li><p>在profile文件末尾添加JDK路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk-11.0.1</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20181209174802.png" alt=""></p><ul><li><p>让修改后的文件生效</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></li><li><p>测试JDK是否安装成功<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20181209174957.png" alt=""></p></li></ul><h2 id="安装Hadoop以及配置环境变量"><a href="#安装Hadoop以及配置环境变量" class="headerlink" title="安装Hadoop以及配置环境变量"></a>安装Hadoop以及配置环境变量</h2><p>Hadoop下载地址：<br><a href="https://archive.apache.org/dist/hadoop/common/hadoop-2.7.7/" target="_blank" rel="noopener">https://archive.apache.org/dist/hadoop/common/hadoop-2.7.7/</a><br>也可以在官网直接下载。</p><h3 id="导入Hadoop软件包"><a href="#导入Hadoop软件包" class="headerlink" title="导入Hadoop软件包"></a>导入Hadoop软件包</h3><p>用Xshell工具将hadoop-2.7.7.tar.gz导入到opt目录下面的software文件夹下面</p><h3 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h3><ul><li><p>进入到Hadoop安装包路径下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/software/</span><br></pre></td></tr></table></figure></li><li><p>解压安装文件到/opt/module下面</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf hadoop-2.7.7.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure></li></ul><h3 id="将Hadoop添加到环境变量"><a href="#将Hadoop添加到环境变量" class="headerlink" title="将Hadoop添加到环境变量"></a>将Hadoop添加到环境变量</h3><ul><li><p>获取Hadoop安装路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[dik@hadoop102 module]$ cd hadoop-2.7.7/</span><br><span class="line">[dik@hadoop102 hadoop-2.7.7]$ pwd</span><br><span class="line">/opt/module/hadoop-2.7.7</span><br></pre></td></tr></table></figure></li><li><p>打开/etc/profile文件,在profile文件末尾添加hadoop路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">##HADOOP_HOME</span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop-2.7.7</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure></li><li><p>让修改后的文件生效</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></li><li><p>测试是否安装成功</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[dik@hadoop102 hadoop-2.7.7]$ hadoop version</span><br><span class="line">Hadoop 2.7.7</span><br><span class="line">Subversion Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac</span><br><span class="line">Compiled by stevel on 2018-07-18T22:47Z</span><br><span class="line">Compiled with protoc 2.5.0</span><br><span class="line">From source with checksum 792e15d20b12c74bd6f19a1fb886490</span><br><span class="line">This command was run using /opt/module/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar</span><br></pre></td></tr></table></figure></li></ul><h2 id="Hadoop目录结构"><a href="#Hadoop目录结构" class="headerlink" title="Hadoop目录结构"></a>Hadoop目录结构</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[dik@hadoop102 hadoop-2.7.7]$ ll</span><br><span class="line">total 116</span><br><span class="line">drwxr-xr-x. 2 dik dik   194 Dec  6 23:56 bin</span><br><span class="line">drwxrwxr-x. 3 dik dik    17 Dec  7 22:50 data</span><br><span class="line">drwxr-xr-x. 3 dik dik    20 Dec  6 23:56 etc</span><br><span class="line">drwxr-xr-x. 2 dik dik   106 Dec  6 23:56 include</span><br><span class="line">drwxrwxr-x. 2 dik dik   187 Dec  6 23:58 input</span><br><span class="line">drwxr-xr-x. 3 dik dik    20 Dec  6 23:56 lib</span><br><span class="line">drwxr-xr-x. 2 dik dik   239 Dec  6 23:56 libexec</span><br><span class="line">-rw-r--r--. 1 dik dik 86424 Dec  6 23:56 LICENSE.txt</span><br><span class="line">drwxrwxr-x. 3 dik dik  4096 Dec  9 09:40 logs</span><br><span class="line">-rw-r--r--. 1 dik dik 14978 Dec  6 23:56 NOTICE.txt</span><br><span class="line">drwxrwxr-x. 2 dik dik    88 Dec  6 23:58 output</span><br><span class="line">-rw-r--r--. 1 dik dik  1366 Dec  6 23:56 README.txt</span><br><span class="line">drwxr-xr-x. 2 dik dik  4096 Dec  8 00:37 sbin</span><br><span class="line">drwxr-xr-x. 4 dik dik    31 Dec  6 23:57 share</span><br></pre></td></tr></table></figure><h3 id="重要目录"><a href="#重要目录" class="headerlink" title="重要目录"></a>重要目录</h3><p>（1）bin目录：存放对Hadoop相关服务（HDFS,YARN）进行操作的脚本<br>（2）etc目录：Hadoop的配置文件目录，存放Hadoop的配置文件<br>（3）lib目录：存放Hadoop的本地库（对数据进行压缩解压缩功能）<br>（4）sbin目录：存放启动或停止Hadoop相关服务的脚本<br>（5）share目录：存放Hadoop的依赖jar包、文档、和官方案例</p><h2 id="本地模式运行Hadoop"><a href="#本地模式运行Hadoop" class="headerlink" title="本地模式运行Hadoop"></a>本地模式运行Hadoop</h2><h3 id="官方Grep案例"><a href="#官方Grep案例" class="headerlink" title="官方Grep案例"></a>官方Grep案例</h3><ul><li><p>创建在hadoop-2.7.7文件下面创建一个input文件夹</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir input</span><br></pre></td></tr></table></figure></li><li><p>将Hadoop的xml配置文件复制到input</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp etc/hadoop/*.xml input</span><br></pre></td></tr></table></figure></li><li><p>执行share目录下的MapReduce程序</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop jar  share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar grep input output &apos;dfs[a-z.]+&apos;</span><br></pre></td></tr></table></figure></li><li><p>查看输出结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat output/*</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20181209185510.png" alt=""></p><p>到这里一个简单的Hadoop运行环境就搭建成功了！</p><hr>]]></content>
    
    <summary type="html">
    
      这是大数据入门的第一篇文章
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>CS224n笔记 自然语言处理与深度学习简介</title>
    <link href="http://yoursite.com/2018/11/11/CS224n%E7%AC%94%E8%AE%B0-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/"/>
    <id>http://yoursite.com/2018/11/11/CS224n笔记-自然语言处理与深度学习简介/</id>
    <published>2018-11-11T07:53:53.000Z</published>
    <updated>2018-12-09T04:09:01.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><p><img src="https://" alt="" style="width:100%"><br>这是斯坦福CS224n的第一篇笔记，也是第一次系统地学习用深度学习来做自然语言处理。<br><a id="more"></a></p><h2 id="什么是自然语言处理"><a href="#什么是自然语言处理" class="headerlink" title="什么是自然语言处理"></a>什么是自然语言处理</h2><p>这是一门计算机科学、人工智能以及语言学的交叉学科。虽然语言只是人工智能的一部分（人工智能还包括计算机视觉等），但它是非常独特的一部分。这个星球上有许多生物拥有超过人类的视觉系统，但只有人类才拥有这么高级的语言。</p><p>自然语言处理的目标是让计算机处理或说“理解”自然语言，以完成有意义的任务，比如订机票购物或QA等。完全理解和表达语言是极其困难的，完美的语言理解等效于实现人工智能。</p><h3 id="自然语言处理涉及的几个层次"><a href="#自然语言处理涉及的几个层次" class="headerlink" title="自然语言处理涉及的几个层次"></a>自然语言处理涉及的几个层次</h3><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181111/1hAAbhCihJ.png?imageslim" alt="mark"></p><p>作为输入一共有两个来源，语音与文本。所以第一级是语音识别和OCR或分词（事实上，跳过分词虽然理所当然地不能做句法分析，但字符级也可以直接做不少应用）。接下来是形态学，援引《统计自然语言处理》中的定义：<br>形态学（morphology）：形态学（又称“词汇形态学”或“词法”）是语言学的一个分支，研究词的内部结构，包括屈折变化和构词法两个部分。由于词具有语音特征、句法特征和语义特征，形态学处于音位学、句法学和语义学的结合部位，所以形态学是每个语言学家都要关注的一门学科［Matthews,2000］。<br>下面的是句法分析和语义分析，最后面的在中文中似乎翻译做“对话分析”，需要根据上文语境理解下文。</p><p>这门课主要关注画圈的三个部分，其中中间的两个是重中之重，虽然深度学习在语音识别上的发力最大。</p><h3 id="自然语言处理应用"><a href="#自然语言处理应用" class="headerlink" title="自然语言处理应用"></a>自然语言处理应用</h3><p>一个小子集，从简单到复杂有：</p><ul><li>拼写检查、关键词检索……</li><li>文本挖掘（产品价格、日期、时间、地点、人名、公司名）</li><li>文本分类</li><li>机器翻译</li><li>客服系统</li><li>复杂对话系统</li></ul><p>在工业界从搜索到广告投放、自动\辅助翻译、情感舆情分析、语音识别、聊天机器人\管家等等五花八门。</p><h3 id="人类语言的特殊之处"><a href="#人类语言的特殊之处" class="headerlink" title="人类语言的特殊之处"></a>人类语言的特殊之处</h3><p>与信号处理、数据挖掘不同，自然语言的随机性小而目的性强；语言是用来传输有意义的信息的，这种传输连小孩子都能很快学会。人类语言是离散的、明确的符号系统。但又允许出现各种变种，比如颜文字，随意的错误拼写“I loooove it”。这种自由性可能是因为语言的可靠性（赘余性）。所以说语言文字绝对不是形式逻辑或传统AI的产物。</p><p>语言符号有多种形式（声音、手势、书写），在这些不同的形式中，其意义保持不变：</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181111/kbKKIc7DL1.png?imageslim" alt="mark"></p><p>虽然人类语言是明确的符号系统，但符号传输到大脑的过程是通过连续的声学光学信号，大脑编码似乎是连续的激活值上的模式。另外巨大的词表也导致数据稀疏，不利于机器学习。这构成一种动机，是不是应该用连续的信号而不是离散的符号去处理语言。</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181111/1AECLm4IIB.png?imageslim" alt="mark"></p><h2 id="什么是深度学习"><a href="#什么是深度学习" class="headerlink" title="什么是深度学习"></a>什么是深度学习</h2><p>这是机器学习的一个子集。传统机器学习中，人类需要对专业问题理解非常透彻，才能手工设计特征。比如地名和机构名识别的特征模板：</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181111/9LHAFLk7B9.png?imageslim" alt="mark"></p><p>然后把特征交给某个机器学习算法，比如线性分类器。机器为这些特征调整找到合适的权值，将误差优化到最小。<br>在这个过程中一直在学习的其实是人类，而不是机器。机器仅仅做了一道数值优化的题目而已。<br>下面这张图很好地展示了这个过程中的比例：</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181111/75hF5GfEbH.png?imageslim" alt="mark"></p><p>而深度学习是表示学习的一部分，用来学习原始输入的多层特征表示：</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181111/Ghe5IafCEF.png?imageslim" alt="mark"></p><h2 id="为什么NLP难"><a href="#为什么NLP难" class="headerlink" title="为什么NLP难"></a>为什么NLP难</h2><p>人类语言是充满歧义的，不像编程语言那样明确。编程语言中有各种变量名，但人类语言中只有少数几个代词可以用，你得思考到底指代的是谁……</p><p>人类语言的解读依赖于现实世界、常识以及上下文。由于说话速度书写速度阅读速度的限制，人类语言非常简练，省略了大量背景知识。</p><h2 id="Deep-NLP-Deep-Learning-NLP"><a href="#Deep-NLP-Deep-Learning-NLP" class="headerlink" title="Deep NLP = Deep Learning + NLP"></a>Deep NLP = Deep Learning + NLP</h2><p>将自然语言处理的思想与表示学习结合起来，用深度学习的手法解决NLP目标。这提高了许多方面的效果：</p><ul><li>层次：语音、词汇、语法、语义</li><li>工具：词性标注、命名实体识别、句法\语义分析</li><li>应用：机器翻译、情感分析、客服系统、问答系统</li></ul><p>深度学习的一个魅力之处是，它提供了一套“宇宙通用”的框架解决了各种问题。虽然工具就那么几个，但在各行各业都适用。</p><h3 id="NLP表示层次：形态级别"><a href="#NLP表示层次：形态级别" class="headerlink" title="NLP表示层次：形态级别"></a>NLP表示层次：形态级别</h3><p>传统方法在形态级别的表示是词素：</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181112/4FhDDl1gik.png?imageslim" alt="mark"></p><p>深度学习中把词素也作为向量：</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181112/flch5ek6gj.png?imageslim" alt="mark"></p><p>多个词素向量构成相同纬度语义更丰富的词向量。</p><h3 id="NLP工具：句法分析"><a href="#NLP工具：句法分析" class="headerlink" title="NLP工具：句法分析"></a>NLP工具：句法分析</h3><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181112/953EejHdL4.png?imageslim" alt="mark"></p><h3 id="NLP语义层面的表示"><a href="#NLP语义层面的表示" class="headerlink" title="NLP语义层面的表示"></a>NLP语义层面的表示</h3><p>传统方法是手写大量的规则函数，叫做Lambda calculus：</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181112/F5k3IK8Bca.png?imageslim" alt="mark"></p><p>在深度学习中，每个句子、短语和逻辑表述都是向量。神经网络负责它们的合并。</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181112/jhBmc2ddED.png?imageslim" alt="mark"></p><h3 id="情感分析"><a href="#情感分析" class="headerlink" title="情感分析"></a>情感分析</h3><p>传统方法是请一两百个工人，手工搜集“情感极性词典”在词袋模型上做分类器。</p><p>深度学习复用了RNN来解决这个问题，它可以识别“反话”的情感极性：</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181112/fKIb87DdkD.png?imageslim" alt="mark"></p><p>注意这只是为了方便理解的示意图，并不是RNN的工作流程。私以为这张图放在这里不合适，可能会误导一部分人，以为神经网络就是这样的基于规则的“决策树”模型。</p><h3 id="客服系统"><a href="#客服系统" class="headerlink" title="客服系统"></a>客服系统</h3><p>最著名的例子得数GMail的自动回复：</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181112/BhhG1CaI8A.png?imageslim" alt="mark"></p><p>这是Neural Language Models的又一次成功应用，Neural Language Models是基于RNN的：</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181112/ef4LC6FBG1.png?imageslim" alt="mark"></p><h3 id="机器翻译"><a href="#机器翻译" class="headerlink" title="机器翻译"></a>机器翻译</h3><p>传统方法在许多层级上做了尝试，词语、语法、语义之类。这类方法试图找到一种世界通用的“国际语”（Interlingua）来作为原文和译文的桥梁。</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181112/26CfkGEekE.png?imageslim" alt="mark"></p><p>而Neural Machine Translation将原文映射为向量，由向量构建译文。也许可以说Neural Machine Translation的“国际语”是向量。</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181112/EFFK2L4liE.png?imageslim" alt="mark"></p><h2 id="结论：所有层级的表示都是向量"><a href="#结论：所有层级的表示都是向量" class="headerlink" title="结论：所有层级的表示都是向量"></a>结论：所有层级的表示都是向量</h2><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181112/bdGC8aC2jB.png?imageslim" alt="mark"></p><p>这可能是因为向量是最灵活的形式，它的维度是自由的，它可以组合成矩阵，或者更高阶的Tensor。事实上，在实践的时候向量和矩阵没什么本质区别，经常看到为了效率或单纯的美观而pack成矩阵unroll成向量的操作。</p><hr>]]></content>
    
    <summary type="html">
    
      CS224n 笔记
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>电力消耗预测</title>
    <link href="http://yoursite.com/2018/10/30/XGBoost%E7%94%B5%E5%8A%9B%E6%B6%88%E8%80%97%E9%A2%84%E6%B5%8B/"/>
    <id>http://yoursite.com/2018/10/30/XGBoost电力消耗预测/</id>
    <published>2018-10-30T12:50:43.000Z</published>
    <updated>2019-03-17T07:34:23.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><p><img src="https://" alt="" style="width:100%"></p><a id="more"></a><h2 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h2><p>企业用电需求预测一直是电力市场营销活动业务难点，大数据与云计算、人工智能等新技术相结合，给传统行业转型升级带来了新的机遇和思考。本项目主要用到开放扬中市高新区1000多家企业的历史用电量数据，通过模型算法预测该地区下一个月的每日总用电量。</p><h2 id="数据采集"><a href="#数据采集" class="headerlink" title="数据采集"></a>数据采集</h2><p>本项目主要用到开放扬中市高新区1000多家企业的历史用电量数据，直接在官网下载csv文件即可。</p><h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190307112734.png" alt=""><br>从上面的图可以看到，原始数据主要由3个维度组成：user_id,record_date,power_consumption,分别对应企业ID，日期以及用电量</p><h3 id="日期格式转换"><a href="#日期格式转换" class="headerlink" title="日期格式转换"></a>日期格式转换</h3><p>因为原数据的日期是strting类型，所以我们需要把它格式转换<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">f = open(<span class="string">'电力数据power_AI.csv'</span>)</span><br><span class="line">df = pd.read_csv(f)</span><br><span class="line">df[<span class="string">'record_date'</span>] = pd.to_datetime(df[<span class="string">'record_date'</span>])</span><br></pre></td></tr></table></figure></p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190307113458.png" alt=""></p><h3 id="统计每日均值"><a href="#统计每日均值" class="headerlink" title="统计每日均值"></a>统计每日均值</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">base_df = df[[&apos;record_date&apos;,&apos;power_consumption&apos;]].groupby(by=&apos;record_date&apos;).agg(&apos;sum&apos;)</span><br><span class="line">base_df = base_df.reset_index()</span><br><span class="line">base_df.head()</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190307114750.png" alt=""></p><h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><p>因为数据只有3个维度，可能会造成欠拟合的情况，所以我们利用日期构建一些特征。</p><h3 id="增加日期特征"><a href="#增加日期特征" class="headerlink" title="增加日期特征"></a>增加日期特征</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">base_df[<span class="string">'dow'</span>] = base_df[<span class="string">'record_date'</span>].apply(<span class="keyword">lambda</span> x: x.dayofweek)</span><br><span class="line">base_df[<span class="string">'doy'</span>] = base_df[<span class="string">'record_date'</span>].apply(<span class="keyword">lambda</span> x: x.dayofyear)</span><br><span class="line">base_df[<span class="string">'day'</span>] = base_df[<span class="string">'record_date'</span>].apply(<span class="keyword">lambda</span> x: x.day)</span><br><span class="line">base_df[<span class="string">'month'</span>] = base_df[<span class="string">'record_date'</span>].apply(<span class="keyword">lambda</span> x: x.month)</span><br><span class="line">base_df[<span class="string">'year'</span>] = base_df[<span class="string">'record_date'</span>].apply(<span class="keyword">lambda</span> x: x.year)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">map_season</span><span class="params">(month)</span>:</span></span><br><span class="line">    month_dic = &#123;<span class="number">1</span>:<span class="number">1</span>, <span class="number">2</span>:<span class="number">1</span>, <span class="number">3</span>:<span class="number">2</span>, <span class="number">4</span>:<span class="number">2</span>, <span class="number">5</span>:<span class="number">3</span>, <span class="number">6</span>:<span class="number">3</span>, <span class="number">7</span>:<span class="number">3</span>, <span class="number">8</span>:<span class="number">3</span>, <span class="number">9</span>:<span class="number">3</span>, <span class="number">10</span>:<span class="number">4</span>, <span class="number">11</span>:<span class="number">4</span>, <span class="number">12</span>:<span class="number">1</span>&#125;</span><br><span class="line">    <span class="keyword">return</span> month_dic[month]</span><br><span class="line"></span><br><span class="line">base_df[<span class="string">'season'</span>] = base_df[<span class="string">'month'</span>].apply(<span class="keyword">lambda</span> x: map_season(x))</span><br><span class="line">base_df.head()</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190307120806.png" alt=""></p><h3 id="增加月度特征"><a href="#增加月度特征" class="headerlink" title="增加月度特征"></a>增加月度特征</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">base_df_stats = new_df = base_df[[<span class="string">'power_consumption'</span>,<span class="string">'year'</span>,<span class="string">'month'</span>]].groupby(by=[<span class="string">'year'</span>, <span class="string">'month'</span>]).agg([<span class="string">'mean'</span>, <span class="string">'std'</span>])</span><br><span class="line">base_df_stats.columns = base_df_stats.columns.droplevel(<span class="number">0</span>)</span><br><span class="line">base_df_stats = base_df_stats.reset_index()</span><br><span class="line">base_df_stats[<span class="string">'1_m_mean'</span>] = base_df_stats[<span class="string">'mean'</span>].shift(<span class="number">1</span>)</span><br><span class="line">base_df_stats[<span class="string">'2_m_mean'</span>] = base_df_stats[<span class="string">'mean'</span>].shift(<span class="number">2</span>)</span><br><span class="line">base_df_stats[<span class="string">'1_m_std'</span>] = base_df_stats[<span class="string">'std'</span>].shift(<span class="number">1</span>)</span><br><span class="line">base_df_stats[<span class="string">'2_m_std'</span>] = base_df_stats[<span class="string">'std'</span>].shift(<span class="number">2</span>)</span><br><span class="line">base_df_stats.head()</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190307141849.png" alt=""></p><h3 id="相关性检测"><a href="#相关性检测" class="headerlink" title="相关性检测"></a>相关性检测</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.set_style(<span class="string">'darkgrid'</span>) <span class="comment">#设定绘图的背景样式</span></span><br><span class="line">sns.set_palette(<span class="string">'muted'</span>) <span class="comment">#设定图表的颜色板</span></span><br><span class="line">plt.style.use(<span class="string">'ggplot'</span>)</span><br><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">mpl.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'FangSong'</span>] <span class="comment"># 指定默认字体</span></span><br><span class="line">mpl.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="keyword">False</span> <span class="comment"># 解决保存图像是负号'-'显示为方块的问题</span></span><br><span class="line">corrmat = data_df[internal_chars].corr() <span class="comment">#计算相关系数</span></span><br><span class="line">f , ax = plt.subplots(figsize = (<span class="number">10</span>,<span class="number">6</span>)) <span class="comment">#设置图标尺寸大小</span></span><br><span class="line">plt.xticks(rotation = <span class="string">'0'</span>)</span><br><span class="line">sns.heatmap(corrmat, square=<span class="keyword">False</span>, linewidths=<span class="number">.8</span>, annot=<span class="keyword">True</span>) <span class="comment">#设置热力图参数</span></span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190307143807.png" alt=""></p><h2 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h2><h3 id="企业与用电量的关系"><a href="#企业与用电量的关系" class="headerlink" title="企业与用电量的关系"></a>企业与用电量的关系</h3><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190307144905.png" alt=""><br>可以看到ID为1416,174,175的企业用电量很大<br>如果有必要可以把这3个企业单独分为1类做处理。</p><h3 id="时间维度与用电量的关系"><a href="#时间维度与用电量的关系" class="headerlink" title="时间维度与用电量的关系"></a>时间维度与用电量的关系</h3><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190307150205.png" alt=""><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190307150226.png" alt=""><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190307150238.png" alt=""><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190307150250.png" alt=""><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190307150302.png" alt=""></p><h2 id="数据建模"><a href="#数据建模" class="headerlink" title="数据建模"></a>数据建模</h2><p>在这个项目中，我们主要用到XGboost这个算法模型</p><h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><p>首先我们用模型默认的参数进行预测<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">df_finall = pd.read_excel(<span class="string">'data_all.xlsx'</span>,sheet_name=<span class="string">'V2'</span>)<span class="comment">#加载数据</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> KFold, train_test_split</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> KFold, train_test_split</span><br><span class="line">X = df_finall.iloc[:,<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line">X[[<span class="string">'dow'</span>,<span class="string">'doy'</span>,<span class="string">'day'</span>,<span class="string">'month'</span>,<span class="string">'year'</span>,<span class="string">'season'</span>]] = X[[<span class="string">'dow'</span>,<span class="string">'doy'</span>,<span class="string">'day'</span>,<span class="string">'month'</span>,<span class="string">'year'</span>,<span class="string">'season'</span>]]\</span><br><span class="line">.astype(str)</span><br><span class="line">y = df_finall.iloc[:,<span class="number">-1</span>]</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=<span class="number">0.3</span>)</span><br><span class="line">xgb1 = XGBRegressor()</span><br><span class="line">xgb1.fit(X_train,y_train)</span><br><span class="line">test_predictions = xgb1.predict(X_test)</span><br><span class="line">r2 = metrics.r2_score(y_test, test_predictions)</span><br><span class="line">r2</span><br></pre></td></tr></table></figure></p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/20190307152339.png" alt=""></p><h3 id="参数微调"><a href="#参数微调" class="headerlink" title="参数微调"></a>参数微调</h3><p>因为XGBoost自带的参数较多，所以我们采用网格搜索的方式对参数进行微调。</p><ul><li><p>Step 1: 选择一组初始参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xgb1 = XGBRegressor(eta=<span class="number">0.01</span>, num_boost_round=<span class="number">50</span>, colsample_bytree=<span class="number">0.5</span>, subsample=<span class="number">0.5</span>,objective=<span class="string">'reg:linear'</span>,seed=<span class="number">27</span>)</span><br></pre></td></tr></table></figure></li><li><p>Step 2: 改变 <code>max_depth</code> 和 <code>min_child_weight</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">xgb_param_grid = &#123;<span class="string">'max_depth'</span>: list(range(<span class="number">4</span>,<span class="number">9</span>)), <span class="string">'min_child_weight'</span>: list((<span class="number">1</span>,<span class="number">3</span>,<span class="number">6</span>))&#125;</span><br><span class="line">grid = GridSearchCV(XGBRegressor(eta=<span class="number">0.01</span>, num_boost_round=<span class="number">50</span>, colsample_bytree=<span class="number">0.5</span>, subsample=<span class="number">0.5</span>,objective=<span class="string">'reg:linear'</span>,seed=<span class="number">27</span>),</span><br><span class="line">                param_grid=xgb_param_grid, cv=<span class="number">5</span>)</span><br><span class="line">grid.fit(X_train, y_train)</span><br><span class="line">grid.grid_scores_, grid.best_params_, grid.best_score_</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">([mean: 0.66566, std: 0.11042, params: &#123;&apos;max_depth&apos;: 4, &apos;min_child_weight&apos;: 1&#125;,</span><br><span class="line">  mean: 0.65945, std: 0.10346, params: &#123;&apos;max_depth&apos;: 4, &apos;min_child_weight&apos;: 3&#125;,</span><br><span class="line">  mean: 0.65507, std: 0.08334, params: &#123;&apos;max_depth&apos;: 4, &apos;min_child_weight&apos;: 6&#125;,</span><br><span class="line">  mean: 0.67838, std: 0.09230, params: &#123;&apos;max_depth&apos;: 5, &apos;min_child_weight&apos;: 1&#125;,</span><br><span class="line">  mean: 0.65974, std: 0.09295, params: &#123;&apos;max_depth&apos;: 5, &apos;min_child_weight&apos;: 3&#125;,</span><br><span class="line">  mean: 0.65113, std: 0.08137, params: &#123;&apos;max_depth&apos;: 5, &apos;min_child_weight&apos;: 6&#125;,</span><br><span class="line">  mean: 0.68250, std: 0.08758, params: &#123;&apos;max_depth&apos;: 6, &apos;min_child_weight&apos;: 1&#125;,</span><br><span class="line">  mean: 0.66546, std: 0.10096, params: &#123;&apos;max_depth&apos;: 6, &apos;min_child_weight&apos;: 3&#125;,</span><br><span class="line">  mean: 0.65293, std: 0.09142, params: &#123;&apos;max_depth&apos;: 6, &apos;min_child_weight&apos;: 6&#125;,</span><br><span class="line">  mean: 0.67734, std: 0.08246, params: &#123;&apos;max_depth&apos;: 7, &apos;min_child_weight&apos;: 1&#125;,</span><br><span class="line">  mean: 0.66691, std: 0.09677, params: &#123;&apos;max_depth&apos;: 7, &apos;min_child_weight&apos;: 3&#125;,</span><br><span class="line">  mean: 0.66142, std: 0.08414, params: &#123;&apos;max_depth&apos;: 7, &apos;min_child_weight&apos;: 6&#125;,</span><br><span class="line">  mean: 0.67381, std: 0.11030, params: &#123;&apos;max_depth&apos;: 8, &apos;min_child_weight&apos;: 1&#125;,</span><br><span class="line">  mean: 0.67931, std: 0.09550, params: &#123;&apos;max_depth&apos;: 8, &apos;min_child_weight&apos;: 3&#125;,</span><br><span class="line">  mean: 0.66090, std: 0.08821, params: &#123;&apos;max_depth&apos;: 8, &apos;min_child_weight&apos;: 6&#125;],</span><br><span class="line"> &#123;&apos;max_depth&apos;: 6, &apos;min_child_weight&apos;: 1&#125;,</span><br><span class="line"> 0.6825025931707269)</span><br></pre></td></tr></table></figure><p>网格搜索发现的最佳结果:<br>{‘max_depth’: 6, ‘min_child_weight’: 1}</p><ul><li>Step 3: 调节 <code>gamma</code> 降低模型过拟合风险.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">xgb_param_grid = &#123;<span class="string">'gamma'</span>:[ <span class="number">0.01</span> * i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">5</span>)]&#125;</span><br><span class="line">grid = GridSearchCV(XGBRegressor(eta=<span class="number">0.01</span>, num_boost_round=<span class="number">50</span>, colsample_bytree=<span class="number">0.5</span>, subsample=<span class="number">0.5</span>,objective=<span class="string">'reg:linear'</span>,seed=<span class="number">27</span>,max_depth=<span class="number">7</span>,min_child_weight=<span class="number">1</span>),</span><br><span class="line">                param_grid=xgb_param_grid, cv=<span class="number">5</span>)</span><br><span class="line">grid.fit(X_train, y_train)</span><br><span class="line">grid.grid_scores_, grid.best_params_, grid.best_score_</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">([mean: 0.67462, std: 0.09512, params: &#123;&apos;gamma&apos;: 0.0&#125;,</span><br><span class="line">  mean: 0.67462, std: 0.09512, params: &#123;&apos;gamma&apos;: 0.01&#125;,</span><br><span class="line">  mean: 0.67462, std: 0.09512, params: &#123;&apos;gamma&apos;: 0.02&#125;,</span><br><span class="line">  mean: 0.67462, std: 0.09512, params: &#123;&apos;gamma&apos;: 0.03&#125;,</span><br><span class="line">  mean: 0.67462, std: 0.09512, params: &#123;&apos;gamma&apos;: 0.04&#125;],</span><br><span class="line"> &#123;&apos;gamma&apos;: 0.0&#125;,</span><br><span class="line"> 0.6746192263207629)</span><br></pre></td></tr></table></figure><p>网格搜索发现的最佳结果:<br>{‘gamma’: 0.0}</p><ul><li>Step 4: 调节 <code>subsample</code> 和 <code>colsample_bytree</code> 改变数据采样策略.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">xgb_param_grid = &#123;<span class="string">'subsample'</span>:[ <span class="number">0.1</span> * i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6</span>,<span class="number">10</span>)],</span><br><span class="line">                      <span class="string">'colsample_bytree'</span>:[ <span class="number">0.1</span> * i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6</span>,<span class="number">10</span>)]&#125;</span><br><span class="line">grid = GridSearchCV(XGBRegressor(eta=<span class="number">0.01</span>, num_boost_round=<span class="number">50</span>, colsample_bytree=<span class="number">0.5</span>, subsample=<span class="number">0.5</span>,objective=<span class="string">'reg:linear'</span>,seed=<span class="number">27</span>,max_depth=<span class="number">7</span>,</span><br><span class="line">                                 min_child_weight=<span class="number">1</span>,gamma=<span class="number">0</span>),</span><br><span class="line">                param_grid=xgb_param_grid, cv=<span class="number">5</span>)</span><br><span class="line">grid.fit(X_train, y_train)</span><br><span class="line">grid.grid_scores_, grid.best_params_, grid.best_score_</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">([mean: 0.67014, std: 0.13270, params: &#123;&apos;colsample_bytree&apos;: 0.6000000000000001, &apos;subsample&apos;: 0.6000000000000001&#125;,</span><br><span class="line">  mean: 0.67302, std: 0.10802, params: &#123;&apos;colsample_bytree&apos;: 0.6000000000000001, &apos;subsample&apos;: 0.7000000000000001&#125;,</span><br><span class="line">  mean: 0.66858, std: 0.11634, params: &#123;&apos;colsample_bytree&apos;: 0.6000000000000001, &apos;subsample&apos;: 0.8&#125;,</span><br><span class="line">  mean: 0.67034, std: 0.11901, params: &#123;&apos;colsample_bytree&apos;: 0.6000000000000001, &apos;subsample&apos;: 0.9&#125;,</span><br><span class="line">  mean: 0.66074, std: 0.12567, params: &#123;&apos;colsample_bytree&apos;: 0.7000000000000001, &apos;subsample&apos;: 0.6000000000000001&#125;,</span><br><span class="line">  mean: 0.67163, std: 0.11620, params: &#123;&apos;colsample_bytree&apos;: 0.7000000000000001, &apos;subsample&apos;: 0.7000000000000001&#125;,</span><br><span class="line">  mean: 0.67011, std: 0.11888, params: &#123;&apos;colsample_bytree&apos;: 0.7000000000000001, &apos;subsample&apos;: 0.8&#125;,</span><br><span class="line">  mean: 0.67345, std: 0.10611, params: &#123;&apos;colsample_bytree&apos;: 0.7000000000000001, &apos;subsample&apos;: 0.9&#125;,</span><br><span class="line">  mean: 0.67388, std: 0.11610, params: &#123;&apos;colsample_bytree&apos;: 0.8, &apos;subsample&apos;: 0.6000000000000001&#125;,</span><br><span class="line">  mean: 0.67462, std: 0.10752, params: &#123;&apos;colsample_bytree&apos;: 0.8, &apos;subsample&apos;: 0.7000000000000001&#125;,</span><br><span class="line">  mean: 0.68473, std: 0.10995, params: &#123;&apos;colsample_bytree&apos;: 0.8, &apos;subsample&apos;: 0.8&#125;,</span><br><span class="line">  mean: 0.69456, std: 0.08956, params: &#123;&apos;colsample_bytree&apos;: 0.8, &apos;subsample&apos;: 0.9&#125;,</span><br><span class="line">  mean: 0.66677, std: 0.11420, params: &#123;&apos;colsample_bytree&apos;: 0.9, &apos;subsample&apos;: 0.6000000000000001&#125;,</span><br><span class="line">  mean: 0.66556, std: 0.10918, params: &#123;&apos;colsample_bytree&apos;: 0.9, &apos;subsample&apos;: 0.7000000000000001&#125;,</span><br><span class="line">  mean: 0.67706, std: 0.11681, params: &#123;&apos;colsample_bytree&apos;: 0.9, &apos;subsample&apos;: 0.8&#125;,</span><br><span class="line">  mean: 0.67529, std: 0.11429, params: &#123;&apos;colsample_bytree&apos;: 0.9, &apos;subsample&apos;: 0.9&#125;],</span><br><span class="line"> &#123;&apos;colsample_bytree&apos;: 0.8, &apos;subsample&apos;: 0.9&#125;,</span><br><span class="line"> 0.6945571414092301)</span><br></pre></td></tr></table></figure><p>网格搜索发现的最佳结果:<br>{‘colsample_bytree’: 0.8, ‘subsample’: 0.9}</p><ul><li>Step 5: 调节学习率 <code>learning_rate</code>.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">xgb_param_grid = &#123;<span class="string">'learning_rate'</span>:[<span class="number">0.6</span>,<span class="number">0.5</span>,<span class="number">0.4</span>,<span class="number">0.3</span>,<span class="number">0.2</span>,<span class="number">0.1</span>,<span class="number">0.01</span>,<span class="number">0.001</span>]&#125;</span><br><span class="line">grid = GridSearchCV(XGBRegressor( num_boost_round=<span class="number">50</span>,objective=<span class="string">'reg:linear'</span>,seed=<span class="number">27</span>,max_depth=<span class="number">7</span>,</span><br><span class="line">                                 min_child_weight=<span class="number">1</span>,gamma=<span class="number">0</span>,colsample_bytree=<span class="number">0.8</span>,subsample=<span class="number">0.9</span>),param_grid=xgb_param_grid, cv=<span class="number">5</span>)</span><br><span class="line">grid.fit(X_train, y_train)</span><br><span class="line">grid.grid_scores_, grid.best_params_, grid.best_score_</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">([mean: 0.56345, std: 0.18185, params: &#123;&apos;learning_rate&apos;: 0.6&#125;,</span><br><span class="line">  mean: 0.60402, std: 0.16560, params: &#123;&apos;learning_rate&apos;: 0.5&#125;,</span><br><span class="line">  mean: 0.67215, std: 0.13258, params: &#123;&apos;learning_rate&apos;: 0.4&#125;,</span><br><span class="line">  mean: 0.63116, std: 0.13087, params: &#123;&apos;learning_rate&apos;: 0.3&#125;,</span><br><span class="line">  mean: 0.62305, std: 0.16146, params: &#123;&apos;learning_rate&apos;: 0.2&#125;,</span><br><span class="line">  mean: 0.69456, std: 0.08956, params: &#123;&apos;learning_rate&apos;: 0.1&#125;,</span><br><span class="line">  mean: -12.66985, std: 4.34214, params: &#123;&apos;learning_rate&apos;: 0.01&#125;,</span><br><span class="line">  mean: -77.40167, std: 26.16110, params: &#123;&apos;learning_rate&apos;: 0.001&#125;],</span><br><span class="line"> &#123;&apos;learning_rate&apos;: 0.1&#125;,</span><br><span class="line"> 0.6945571414092301)</span><br></pre></td></tr></table></figure><p>网格搜索发现的最佳结果:<br>{‘learning_rate’: 0.1}</p><ul><li>step 6:调节<code>n_estimators</code>的棵数<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">xgb_param_grid = &#123;<span class="string">'n_estimators'</span>:[<span class="number">50</span>,<span class="number">100</span>,<span class="number">200</span>,<span class="number">300</span>,<span class="number">400</span>,<span class="number">500</span>]&#125;</span><br><span class="line">grid = GridSearchCV(XGBRegressor( learning_rate=<span class="number">0.1</span>,objective=<span class="string">'reg:linear'</span>,seed=<span class="number">27</span>,max_depth=<span class="number">7</span>,</span><br><span class="line">                                 min_child_weight=<span class="number">1</span>,gamma=<span class="number">0</span>,colsample_bytree=<span class="number">0.8</span>,subsample=<span class="number">0.9</span>),param_grid=xgb_param_grid, cv=<span class="number">5</span>)</span><br><span class="line">grid.fit(X_train, y_train)</span><br><span class="line">grid.grid_scores_, grid.best_params_, grid.best_score_</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">([mean: 0.69015, std: 0.08067, params: &#123;&apos;n_estimators&apos;: 50&#125;,</span><br><span class="line">  mean: 0.69456, std: 0.08956, params: &#123;&apos;n_estimators&apos;: 100&#125;,</span><br><span class="line">  mean: 0.69296, std: 0.09306, params: &#123;&apos;n_estimators&apos;: 200&#125;,</span><br><span class="line">  mean: 0.69270, std: 0.09327, params: &#123;&apos;n_estimators&apos;: 300&#125;,</span><br><span class="line">  mean: 0.69269, std: 0.09334, params: &#123;&apos;n_estimators&apos;: 400&#125;,</span><br><span class="line">  mean: 0.69270, std: 0.09335, params: &#123;&apos;n_estimators&apos;: 500&#125;],</span><br><span class="line"> &#123;&apos;n_estimators&apos;: 100&#125;,</span><br><span class="line"> 0.6945571414092301)</span><br></pre></td></tr></table></figure><p>网格搜索发现的最佳结果:<br>{‘n_estimators’: 100}<br>模型最终的参数为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">XGBRegressor( learning_rate=0.1,</span><br><span class="line">               objective=&apos;reg:linear&apos;,</span><br><span class="line">               seed=27,max_depth=7,</span><br><span class="line">               min_child_weight=1,</span><br><span class="line">               gamma=0,</span><br><span class="line">               colsample_bytree=0.8,</span><br><span class="line">               subsample=0.9)</span><br></pre></td></tr></table></figure></p><p>最终评分：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">xgb3 = XGBRegressor( learning_rate=<span class="number">0.1</span>,objective=<span class="string">'reg:linear'</span>,seed=<span class="number">27</span>,max_depth=<span class="number">7</span>,</span><br><span class="line">                                 min_child_weight=<span class="number">1</span>,gamma=<span class="number">0</span>,colsample_bytree=<span class="number">0.8</span>,subsample=<span class="number">0.9</span>)</span><br><span class="line">xgb3.fit(X_train,y_train)</span><br><span class="line">test_predictions = xgb3.predict(X_test)</span><br><span class="line">r2 = metrics.r2_score(y_test, test_predictions)</span><br><span class="line">r2</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.7133043132603486</span><br></pre></td></tr></table></figure><hr>]]></content>
    
    <summary type="html">
    
      用python机器学习预测电力消耗的问题
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>机器学习-决策树&amp;随机森林算法笔记与实战</title>
    <link href="http://yoursite.com/2018/10/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E7%AE%97%E6%B3%95%E5%AE%9E%E6%88%98/"/>
    <id>http://yoursite.com/2018/10/14/机器学习-决策树-随机森林算法实战/</id>
    <published>2018-10-14T08:05:57.000Z</published>
    <updated>2018-12-09T04:08:34.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><p><img src="https://" alt="" style="width:100%"></p><a id="more"></a><h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><ul><li>决策树：从根节点开始一步步走到叶子节点（决策）</li><li>所有的数据最终都会落到叶子节点，既可以做分类也可以做回归</li></ul><h3 id="树的组成"><a href="#树的组成" class="headerlink" title="树的组成"></a>树的组成</h3><ul><li>根节点：第一个选择点</li><li>非叶子节点与分支：中间过程</li><li>叶子节点：最终的决策结果</li></ul><h3 id="决策树的训练与测试"><a href="#决策树的训练与测试" class="headerlink" title="决策树的训练与测试"></a>决策树的训练与测试</h3><ul><li>训练阶段：从给定的训练集构造出来一棵树（从跟节点开始选择特征， 如何进行特征切分）</li><li>测试阶段：根据构造出来的树模型从上到下去走一遍就好了</li><li>一旦构造好了决策树，那么分类或者预测任务就很简单了，只需要走一遍 就可以了，那么难点就在于如何构造出来一颗树，这就没那么容易了，需 要考虑的问题还有很多的！</li></ul><h3 id="如何切分特征（选择节点）"><a href="#如何切分特征（选择节点）" class="headerlink" title="如何切分特征（选择节点）"></a>如何切分特征（选择节点）</h3><ul><li>问题：根节点的选择该用哪个特征呢？接下来呢？如何切分呢？</li><li>想象一下：我们的目标应该是根节点就像一个老大似的能更好的切分数据 （分类的效果更好），根节点下面的节点自然就是二当家了。</li><li>目标：通过一种衡量标准，来计算通过不同特征进行分支选择后的分类 情况，找出来最好的那个当成根节点，以此类推。</li></ul><h3 id="衡量标准-熵"><a href="#衡量标准-熵" class="headerlink" title="衡量标准-熵"></a>衡量标准-熵</h3><ul><li>熵：熵是表示随机变量不确定性的度量 （解释：说白了就是物体内部的混乱程度，比如杂货市场里面什么都有 那肯定混乱呀，专卖店里面只卖一个牌子的那就稳定多啦）</li><li>公式：H(X)=- ∑ pi * logpi, i=1,2, … , n</li><li>一个栗子： A集合[1,1,1,1,1,1,1,1,2,2] <pre><code>      B集合[1,2,3,4,5,6,7,8,9,1]</code></pre>显然A集合的熵值要低，因为A里面只有两种类别，相对稳定一些 而B中类别太多了，熵值就会大很多。（在分类任务中我们希望通过 节点分支后数据类别的熵值大还是小呢？）</li></ul><h3 id="衡量标准-熵-1"><a href="#衡量标准-熵-1" class="headerlink" title="衡量标准-熵"></a>衡量标准-熵</h3><ul><li><p>熵：不确定性越大，得到的熵值也就越大<br>当p=0或p=1时，H(p)=0,随机变量完全没有不确定性<br>当p=0.5时，H(p)=1,此时随机变量的不确定性最大</p></li><li><p>信息增益：表示特征X使得类Y的不确定性减少的程度。 （分类后的专一性，希望分类后的结果是同类在一起）</p></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181015/Ddlh1mI2C2.png?imageslim" alt="mark"></p><h3 id="决策树构造实例"><a href="#决策树构造实例" class="headerlink" title="决策树构造实例"></a>决策树构造实例</h3><p>数据：14天打球情况<br>特征：4种环境变化<br>目标：构造决策树</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181015/8b7iji2662.png?imageslim" alt="mark"></p><p>划分方式：4种<br>问题：谁当根节点呢？<br>依据：信息增益</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181015/J5mJ0BfHJ2.png?imageslim" alt="mark"></p><p>在历史数据中（14天）有9天打球，5天不打球，所以此时的熵应为：</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181015/7f759EB6bd.png?imageslim" alt="mark"></p><p>4个特征逐一分析，先从outlook特征开始：<br>Outlook = sunny时，熵值为0.971<br>Outlook = overcast时，熵值为0<br>Outlook = rainy时，熵值为0.971</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181015/1CdmaCmI8a.png?imageslim" alt="mark"></p><p>根据数据统计，outlook取值分别为sunny,overcast,rainy的概率分别为： 5/14, 4/14, 5/14<br>熵值计算：5/14 <em> 0.971 + 4/14 </em> 0 + 5/14 * 0.971 = 0.693<br>（gain(temperature)=0.029 gain(humidity)=0.152 gain(windy)=0.048）<br>信息增益：系统的熵值从原始的0.940下降到了0.693，增益为0.247<br>同样的方式可以计算出其他特征的信息增益，那么我们选择最大的那个 就可以啦，相当于是遍历了一遍特征，找出来了大当家，然后再其余的 中继续通过信息增益找二当家！</p><h3 id="决策树算法"><a href="#决策树算法" class="headerlink" title="决策树算法"></a>决策树算法</h3><ul><li>ID3：信息增益</li><li>C4.5：信息增益率</li><li>CART：使用GINI系数来当做衡量标准</li><li>GINI系数：和熵的衡量标准类似，计算方式不相同</li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181016/EF2GjH5aH1.png?imageslim" alt="mark"></p><h3 id="决策树剪枝策略"><a href="#决策树剪枝策略" class="headerlink" title="决策树剪枝策略"></a>决策树剪枝策略</h3><p>为什么要剪枝：决策树过拟合风险很大，理论上可以完全分得开数据 （想象一下，如果树足够庞大，每个叶子节点不就一个数据了嘛）<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181016/JcchdK1JcH.png?imageslim" alt="mark"></p><p>剪枝策略：预剪枝，后剪枝</p><ul><li><p>预剪枝：边建立决策树边进行剪枝的操作（更实用）<br>限制深度，叶子节点个数 叶子节点样本数，信息增益量等</p></li><li><p>后剪枝：当建立完决策树后来进行剪枝操作<br>通过一定的衡量标准<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181016/Eg79EDG7b4.png?imageslim" alt="mark"></p></li></ul><h2 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h2><p>随机森林是一种集成算法，是Bagging模型( bootstrap aggregation)的一种典型算法，随机指的是数据采样随机，特征选择随机。森林指的是很多个决策树并行放在一起。</p><h3 id="构造树模型"><a href="#构造树模型" class="headerlink" title="构造树模型"></a>构造树模型</h3><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181016/AmaHLH3K9g.png?imageslim" alt="mark"></p><p>由于二重随机性，使得每个树基本上都不会一样，最终的结果也会不一样</p><h3 id="随机森林优势"><a href="#随机森林优势" class="headerlink" title="随机森林优势"></a>随机森林优势</h3><ul><li>它能够处理很高维度（feature很多）的数据，并且不用做特征选择</li><li>在训练完后，它能够给出哪些feature比较重要</li><li>容易做成并行化方法，速度比较快</li><li>可以进行可视化展示，便于分析</li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/181016/bAK3LL09Ba.png?imageslim" alt="mark"></p><hr>]]></content>
    
    <summary type="html">
    
      决策树&amp;随机森林算法原理以及实战
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Flask入门-搭建图书管理项目</title>
    <link href="http://yoursite.com/2018/09/16/Flask%E5%85%A5%E9%97%A8-%E6%90%AD%E5%BB%BA%E5%9B%BE%E4%B9%A6%E7%AE%A1%E7%90%86%E9%A1%B9%E7%9B%AE/"/>
    <id>http://yoursite.com/2018/09/16/Flask入门-搭建图书管理项目/</id>
    <published>2018-09-16T03:41:02.000Z</published>
    <updated>2018-12-09T04:08:43.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><p><img src="https://" alt="" style="width:100%"><br>在使用了一段django之后发现django太过于冗余，而简洁的Flask貌似更适合我。<br><a id="more"></a></p><h2 id="搭建环境"><a href="#搭建环境" class="headerlink" title="搭建环境"></a>搭建环境</h2><p>在这里推介大家使用pipenv这个虚拟环境</p><ul><li><p>安装pipenv</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pipenv</span><br></pre></td></tr></table></figure></li><li><p>建立虚拟环境</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pipenv install</span><br></pre></td></tr></table></figure></li></ul><p>然后在这个文件夹内会创建2个文件<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180916/h16IGI1kEL.png?imageslim" alt="mark"></p><ul><li><p>启动虚拟环境</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pipenv shell</span><br></pre></td></tr></table></figure></li><li><p>安装flask</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pipenv install flask</span><br></pre></td></tr></table></figure></li></ul><p>打开pycharm，把刚刚搭建的虚拟环境配置到其中。</p><p>到这里，虚拟环境就已经配置完成啦！</p><h2 id="配置数据库"><a href="#配置数据库" class="headerlink" title="配置数据库"></a>配置数据库</h2><p>在图管理这个项目中需要用到Mysql这个数据库</p><h3 id="导入SQLALchemy扩展"><a href="#导入SQLALchemy扩展" class="headerlink" title="导入SQLALchemy扩展"></a>导入SQLALchemy扩展</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask_sqlalchemy <span class="keyword">import</span> SQLAlchemy</span><br><span class="line"><span class="comment">## 数据库配置：数据库地址/关闭自动跟踪修改</span></span><br><span class="line">app.config[<span class="string">'SQLALCHEMY_DATABASE_URI'</span>] = <span class="string">'mysql://root:root@127.0.0.1/flask_books'</span></span><br><span class="line">app.config[<span class="string">'SQLALCHEMY_TRACK_MODIFICATIONS'</span>]=<span class="keyword">False</span></span><br></pre></td></tr></table></figure><p>需要注意的是在使用flask_sqlalchemy的时候可能会有<strong>ImportError: No module named MySQLdb</strong></p><p>这里有个解决的办法就是到 <a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#" target="_blank" rel="noopener">https://www.lfd.uci.edu/~gohlke/pythonlibs/#</a> 这里下载<strong>mysqlclient</strong>然后自行安装。</p><h3 id="创建db对象-并配置参数"><a href="#创建db对象-并配置参数" class="headerlink" title="创建db对象,并配置参数"></a>创建db对象,并配置参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 数据库配置：数据库地址/关闭自动跟踪修改</span></span><br><span class="line">app.config[<span class="string">'SQLALCHEMY_DATABASE_URI'</span>] = <span class="string">'mysql://root:root@127.0.0.1/flask_books'</span></span><br><span class="line">app.config[<span class="string">'SQLALCHEMY_TRACK_MODIFICATIONS'</span>]=<span class="keyword">False</span></span><br></pre></td></tr></table></figure><h3 id="创建数据库-amp-添加数据"><a href="#创建数据库-amp-添加数据" class="headerlink" title="创建数据库&amp;添加数据"></a>创建数据库&amp;添加数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">db.drop_all()</span><br><span class="line">db.create_all()</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成数据</span></span><br><span class="line">au1 = Author(name=<span class="string">'老王'</span>)</span><br><span class="line">au2 = Author(name=<span class="string">'老惠'</span>)</span><br><span class="line">au3 = Author(name=<span class="string">'老刘'</span>)</span><br><span class="line">db.session.add_all([au1,au2,au3])</span><br><span class="line">db.session.commit()</span><br><span class="line"></span><br><span class="line">bk1 = Book(name= <span class="string">'老王回忆录'</span>,author_id=au1.id)</span><br><span class="line">bk2 = Book(name=<span class="string">'我读书少，你别骗我'</span>, author_id=au1.id)</span><br><span class="line">bk3 = Book(name=<span class="string">'如何才能让自己更骚'</span>, author_id=au2.id)</span><br><span class="line">bk4 = Book(name=<span class="string">'怎样征服美丽少女'</span>, author_id=au3.id)</span><br><span class="line">bk5 = Book(name=<span class="string">'如何征服英俊少男'</span>, author_id=au3.id)</span><br><span class="line">db.session.add_all([bk1,bk2,bk3,bk4,bk5])</span><br><span class="line">db.session.commit()</span><br></pre></td></tr></table></figure><h2 id="添加书和作者模型"><a href="#添加书和作者模型" class="headerlink" title="添加书和作者模型"></a>添加书和作者模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##a.模型继承ab.Model</span></span><br><span class="line"><span class="comment">##b.__tablename__表名</span></span><br><span class="line"><span class="comment">##c.db.Column:字段</span></span><br><span class="line"><span class="comment">##d.relationship :关系引用</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Author</span><span class="params">(db.Model)</span>:</span></span><br><span class="line">    <span class="comment"># 表名</span></span><br><span class="line"></span><br><span class="line">    __tablename__ = <span class="string">'authors'</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#字段</span></span><br><span class="line">    id = db.Column(db.Integer,primary_key=<span class="keyword">True</span>)</span><br><span class="line">    name = db.Column(db.String(<span class="number">16</span>),unique=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#关系引用</span></span><br><span class="line">    books = db.relationship(<span class="string">'Book'</span>,backref=<span class="string">'author'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">'Author:%s'</span> % self.name</span><br><span class="line"></span><br><span class="line"><span class="comment">##书籍模型</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Book</span><span class="params">(db.Model)</span>:</span></span><br><span class="line">    __tablename__ = <span class="string">'books'</span></span><br><span class="line"></span><br><span class="line">    id = db.Column(db.Integer,primary_key=<span class="keyword">True</span>)</span><br><span class="line">    name = db.Column(db.String(<span class="number">16</span>) , unique=<span class="keyword">True</span>)</span><br><span class="line">    author_id = db.Column(db.Integer,db.ForeignKey(<span class="string">'authors.id'</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">'Book:%s %s'</span> % (self.name,self.author_id)</span><br></pre></td></tr></table></figure><h2 id="使用模板显示数据库查询的数据"><a href="#使用模板显示数据库查询的数据" class="headerlink" title="使用模板显示数据库查询的数据"></a>使用模板显示数据库查询的数据</h2><h3 id="查询所有的作者信息，让信息传递给模板"><a href="#查询所有的作者信息，让信息传递给模板" class="headerlink" title="查询所有的作者信息，让信息传递给模板"></a>查询所有的作者信息，让信息传递给模板</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">authors = Author.query.all()</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> render_template(<span class="string">'books.html'</span>,authors = authors)</span><br></pre></td></tr></table></figure><h3 id="模板中按照格式，依次for循环作者和书籍（作者获取书籍，用的是关系引用）"><a href="#模板中按照格式，依次for循环作者和书籍（作者获取书籍，用的是关系引用）" class="headerlink" title="模板中按照格式，依次for循环作者和书籍（作者获取书籍，用的是关系引用）"></a>模板中按照格式，依次for循环作者和书籍（作者获取书籍，用的是关系引用）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="comment">#先遍历作者，然后在作者里面遍历书籍#&#125;</span></span><br><span class="line">&lt;ul&gt;</span><br><span class="line">&#123;% <span class="keyword">for</span> author <span class="keyword">in</span> authors %&#125;</span><br><span class="line">&lt;li&gt;&#123;&#123; author.name &#125;&#125;&lt;a href="&#123;&#123; url_for("delete_author",author_id = author.id) &#125;&#125;"&gt;删除&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">    &lt;ul&gt;</span><br><span class="line">    &#123;% <span class="keyword">for</span> book <span class="keyword">in</span> author.books %&#125;</span><br><span class="line">            &lt;li&gt;&#123;&#123; book.name &#125;&#125; &lt;a href="&#123;&#123; url_for("delete_book",book_id = book.id) &#125;&#125;"&gt;删除&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">    &#123;% <span class="keyword">else</span> %&#125;</span><br><span class="line">            &lt;li&gt;无&lt;/li&gt;</span><br><span class="line"></span><br><span class="line">    &#123;% endfor %&#125;</span><br><span class="line"></span><br><span class="line">    &lt;/ul&gt;</span><br><span class="line">&#123;% endfor %&#125;</span><br></pre></td></tr></table></figure><h3 id="使用WTF显示表单"><a href="#使用WTF显示表单" class="headerlink" title="使用WTF显示表单"></a>使用WTF显示表单</h3><h3 id="自定义表单类"><a href="#自定义表单类" class="headerlink" title="自定义表单类"></a>自定义表单类</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask_wtf <span class="keyword">import</span> FlaskForm</span><br><span class="line"><span class="keyword">from</span> wtforms <span class="keyword">import</span> StringField,SubmitField</span><br><span class="line"></span><br><span class="line"><span class="comment">##自定义表单类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AuthorForm</span><span class="params">(FlaskForm)</span>:</span></span><br><span class="line">    author = StringField(<span class="string">'作者'</span>,validators=[DataRequired()])</span><br><span class="line">    book = StringField(<span class="string">'书籍'</span>, validators=[DataRequired()])</span><br><span class="line">    submit = SubmitField(<span class="string">'提交'</span>)</span><br></pre></td></tr></table></figure><h3 id="模板中显示"><a href="#模板中显示" class="headerlink" title="模板中显示"></a>模板中显示</h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">method</span>=<span class="string">"post"</span>&gt;</span></span><br><span class="line">    &#123;&#123; form.csrf_token() &#125;&#125;</span><br><span class="line">    &#123;&#123; form.author.label &#125;&#125;&#123;&#123; form.author &#125;&#125;<span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">    &#123;&#123; form.book.label &#125;&#125;&#123;&#123; form.book &#125;&#125;<span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">    &#123;&#123; form.submit &#125;&#125;<span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">    &#123;#  显示消息闪现的内容 #&#125;</span><br><span class="line">    &#123;% for message in get_flashed_messages() %&#125;</span><br><span class="line">        &#123;&#123; message &#125;&#125;</span><br><span class="line">    &#123;% endfor %&#125;</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="消息闪现：secret-key-csrf-token"><a href="#消息闪现：secret-key-csrf-token" class="headerlink" title="消息闪现：secret_key/csrf_token"></a>消息闪现：secret_key/csrf_token</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> flash</span><br><span class="line">app.secret_key=<span class="string">'baidu'</span></span><br></pre></td></tr></table></figure><ul><li>secret_key的作用</li></ul><p>引用一段 Flask Web Development 中的内容:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SECRET_KEY 配置变量是通用密钥, 可在 Flask 和多个第三方扩展中使用. </span><br><span class="line">如其名所示, 加密的强度取决于变量值的机密度. </span><br><span class="line">不同的程序要使用不同的密钥, 而且要保证其他人不知道你所用的字符串.</span><br></pre></td></tr></table></figure></p><p>SECRET_KEY 的作用主要是提供一个值做各种 HASH, 我没有实际研究过源码, 不同框架和第三方库的功能也不尽相同, 我不能给出准确的答案, 但是主要的作用应该是在其加密过程中作为算法的一个参数(salt 或其他). 所以这个值的复杂度也就影响到了数据传输和存储时的复杂度.</p><ul><li>csrf_token()<br>简单说来，使用它可以方便我们构建表单和验证表单，具体用法这里不做赘述<br>详细说明以及用法请到 <a href="https://blog.csdn.net/baidu_35085676/article/details/78254954" target="_blank" rel="noopener">https://blog.csdn.net/baidu_35085676/article/details/78254954</a></li></ul><h2 id="实现相关的增删逻辑"><a href="#实现相关的增删逻辑" class="headerlink" title="实现相关的增删逻辑"></a>实现相关的增删逻辑</h2><h3 id="增加书籍"><a href="#增加书籍" class="headerlink" title="增加书籍"></a>增加书籍</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">验证逻辑：</span></span><br><span class="line"><span class="string">1.调用WTF的函数实现验证</span></span><br><span class="line"><span class="string">2.验证通过获取数据</span></span><br><span class="line"><span class="string">3.判断作者是否存在</span></span><br><span class="line"><span class="string">4.如果作者存在，判断书籍是否存在，没有重复书籍，添加数据，如果重复就提示错误</span></span><br><span class="line"><span class="string">5.如果作者不存在，添加作者和书籍</span></span><br><span class="line"><span class="string">6.验证不通过就提示错误</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.调用WTF的函数实现验证</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> author_form.validate_on_submit():</span><br><span class="line">    <span class="comment">#2.验证通过获取数据</span></span><br><span class="line">    author_name = author_form.author.data</span><br><span class="line">    book_name = author_form.book.data</span><br><span class="line"></span><br><span class="line">    <span class="comment">#3.判断作者是否存在</span></span><br><span class="line">    author = Author.query.filter_by(name = author_name).first()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#4.如果作者存在</span></span><br><span class="line">    <span class="keyword">if</span> author:</span><br><span class="line">        <span class="comment">#判断书籍是否存在，没有重复书籍，添加数据</span></span><br><span class="line">        book = Book.query.filter_by(name=book_name).first()</span><br><span class="line">        <span class="keyword">if</span> book:</span><br><span class="line">            flash(<span class="string">'已存在同名书籍'</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                new_book = Book(name=book_name,author_id=author.id)</span><br><span class="line">                db.session.add(new_book)</span><br><span class="line">                db.session.commit(  )</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                print(e)</span><br><span class="line">                flash(<span class="string">'添加书籍失败'</span>)</span><br><span class="line">                db.session.rollback() <span class="comment">#回滚</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment">#5.如果作者不存在，添加作者和书籍</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            new_author = Author(name=author_name)</span><br><span class="line">            db.session.add(new_author)</span><br><span class="line">            db.session.commit()</span><br><span class="line"></span><br><span class="line">            new_book=Book(name=book_name,author_id=new_author.id)</span><br><span class="line">            db.session.add(new_book)</span><br><span class="line">            db.session.commit()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            print(e)</span><br><span class="line">            flash(<span class="string">'添加作者和书籍失败'</span>)</span><br><span class="line">            db.session.rollback()</span><br><span class="line"></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">if</span> request.method == <span class="string">'POST'</span>:</span><br><span class="line">        flash(<span class="string">'参数不全'</span>)</span><br><span class="line"></span><br><span class="line">authors = Author.query.all()</span><br><span class="line"><span class="keyword">return</span> render_template(<span class="string">'books.html'</span>,authors = authors,form=author_form)</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180917/FHhd4F3HH9.png?imageslim" alt="mark"></p><h3 id="删除书籍"><a href="#删除书籍" class="headerlink" title="删除书籍"></a>删除书籍</h3><p>删除书籍— 网页中删除 —点击需要发送书籍的ID—路由需要接受参数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">@app.route('/delete_book/&lt;book_id&gt;')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">delete_book</span><span class="params">(book_id)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1.查询数据库，是否有该ID的书，如果有就删除，没有就提示错误</span></span><br><span class="line">    book = Book.query.get(book_id)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.如果有就删除</span></span><br><span class="line">    <span class="keyword">if</span> book:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            db.session.delete(book)</span><br><span class="line">            db.session.commit()</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            print(e)</span><br><span class="line">            flash(<span class="string">'删除书籍出错'</span>)</span><br><span class="line">            db.SessionExtension.rollback()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 3.没有提示错误</span></span><br><span class="line">        flash(<span class="string">'书籍找不到'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># redirect:重定向，需要传入网络/路由地址</span></span><br><span class="line">    <span class="comment"># url_for('index'):需要传入视图函数名，返回该视图函数对应的路由地址</span></span><br><span class="line">    <span class="keyword">return</span> redirect(url_for(<span class="string">'index'</span>))</span><br></pre></td></tr></table></figure></p><h3 id="删除作者"><a href="#删除作者" class="headerlink" title="删除作者"></a>删除作者</h3><p>删除作者具体的思路跟删除书籍差不多<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@app.route('/delete_author/&lt;author_id&gt;')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">delete_author</span><span class="params">(author_id)</span>:</span></span><br><span class="line">    <span class="comment"># 查询数据库，是否有该ID的作者，如果有就删除(先删书，再删作者)，没有就提示错误</span></span><br><span class="line">    <span class="comment"># 1.查询数据库</span></span><br><span class="line">    author = Author.query.get(author_id)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.如果有就删除(先删书，再删作者)</span></span><br><span class="line">    <span class="keyword">if</span> author:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment">#查询之后直接删除</span></span><br><span class="line">            Book.query.filter_by(author_id=author_id).delete()</span><br><span class="line"></span><br><span class="line">            <span class="comment">#删除作者</span></span><br><span class="line">            db.session.delete(author)</span><br><span class="line">            db.session.commit()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            print(e)</span><br><span class="line">            flash(<span class="string">'删除作者出错'</span>)</span><br><span class="line">            db.session.rollback()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        flash(<span class="string">'作者找不到'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> redirect(url_for(<span class="string">'index'</span>))</span><br></pre></td></tr></table></figure></p><p>到这里一个简单的图书管理网站就已经做好啦，完整的项目代码：</p><p><a href="https://github.com/dik111/Flask_book_project" target="_blank" rel="noopener">https://github.com/dik111/Flask_book_project</a></p><hr>]]></content>
    
    <summary type="html">
    
      这个Flask一个简单的入门笔记
    
    </summary>
    
      <category term="网站搭建" scheme="http://yoursite.com/categories/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="网站搭建" scheme="http://yoursite.com/tags/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/"/>
    
      <category term="Flask" scheme="http://yoursite.com/tags/Flask/"/>
    
  </entry>
  
  <entry>
    <title>django入门-搭建字数统计网站</title>
    <link href="http://yoursite.com/2018/09/01/django%E6%90%AD%E5%BB%BA%E5%AD%97%E6%95%B0%E7%BB%9F%E8%AE%A1%E7%BD%91%E7%AB%99/"/>
    <id>http://yoursite.com/2018/09/01/django搭建字数统计网站/</id>
    <published>2018-09-01T14:52:05.000Z</published>
    <updated>2018-12-09T04:34:26.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><p><img src="https://" alt="" style="width:100%"><br>最近工作需要在数据分析系统中增加一些机器学习有关的工具，因为部门里面有些人不会python,为了方便大家使用，所以用django搭建一个网站。<br><a id="more"></a></p><h2 id="安装django"><a href="#安装django" class="headerlink" title="安装django"></a>安装django</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install django</span><br></pre></td></tr></table></figure><h2 id="新建项目"><a href="#新建项目" class="headerlink" title="新建项目"></a>新建项目</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">django-admin startproject wordcount2</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180902/0B9d0edHHL.png?imageslim" alt="mark"></p><h2 id="启动本地服务器"><a href="#启动本地服务器" class="headerlink" title="启动本地服务器"></a>启动本地服务器</h2><p>进入新建的项目文件夹</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python manage.py runserver</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180902/1DBC7LcK1J.png?imageslim" alt="mark"><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180902/2fF6g5mimC.png?imageslim" alt="mark"><br>如果你看到这个页面，就表示你的django安装成功啦！</p><h2 id="新建主页"><a href="#新建主页" class="headerlink" title="新建主页"></a>新建主页</h2><ul><li><p>在wordcount2文件夹中新建templates文件夹，用于存放html文件<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180902/BDF4550hfh.png?imageslim" alt="mark"></p></li><li><p>在templates文件夹中新建home.html文件<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180902/kKGJEDL16j.png?imageslim" alt="mark"></p></li></ul><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>字数统计<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h1</span>&gt;</span>字数统计<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">form</span> &gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">textarea</span> <span class="attr">cols</span>=<span class="string">"100"</span> <span class="attr">rows</span>=<span class="string">"25"</span> <span class="attr">name</span>=<span class="string">"text"</span>&gt;</span>在此输入文本<span class="tag">&lt;/<span class="name">textarea</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"submit"</span> <span class="attr">value</span>=<span class="string">"统计"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"about"</span>&gt;</span>关于本页<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>配置settings.py文件<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180902/k8Ic1F6kBA.png?imageslim" alt="mark"></li></ul><p>在这里我们需要配置settings.py文件，用来告诉django，我们的html文件在哪。</p><ul><li>新增function.py文件</li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180902/K1H2KJChIF.png?imageslim" alt="mark"></p><p>在wordcount2文件夹中新增function.py文件，并且新增home函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">home</span><span class="params">(request)</span>:</span></span><br><span class="line">    <span class="keyword">return</span>  render(request,<span class="string">'home.html'</span>)</span><br></pre></td></tr></table></figure><h3 id="render函数："><a href="#render函数：" class="headerlink" title="render函数："></a>render函数：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">request: 是一个固定参数, 没什么好讲的。</span><br><span class="line"></span><br><span class="line">template_name: templates 中定义的文件, 要注意路径名. 比如<span class="string">'templates\polls\index.html'</span>, 参数就要写‘polls\index.html’</span><br><span class="line"></span><br><span class="line">context: 要传入文件中用于渲染呈现的数据, 默认是字典格式</span><br><span class="line"></span><br><span class="line">content_type: 生成的文档要使用的MIME 类型。默认为DEFAULT_CONTENT_TYPE 设置的值。</span><br><span class="line"></span><br><span class="line">status: http的响应代码,默认是<span class="number">200.</span></span><br><span class="line"></span><br><span class="line">using: 用于加载模板使用的模板引擎的名称。</span><br></pre></td></tr></table></figure><ul><li>配置在urls.py文件</li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180902/ca2i3H6Khd.png?imageslim" alt="mark"><br>在urls.py文件中，需要我们配置网站地址以及映射的函数。</p><p>在这里首页已经配置完成啦！<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180902/CbI35ciFmi.png?imageslim" alt="mark"></p><h2 id="增加统计结果网页"><a href="#增加统计结果网页" class="headerlink" title="增加统计结果网页"></a>增加统计结果网页</h2><p>当用户把需要统计的文字填入文字框中，并且按统计按钮之后，我们的页面需要跳转到统计结果的页面中。</p><ul><li>配置home.html文件<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>字数统计<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h1</span>&gt;</span>字数统计<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">"count"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">textarea</span> <span class="attr">cols</span>=<span class="string">"100"</span> <span class="attr">rows</span>=<span class="string">"25"</span> <span class="attr">name</span>=<span class="string">"text"</span>&gt;</span>在此输入文本<span class="tag">&lt;/<span class="name">textarea</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"submit"</span> <span class="attr">value</span>=<span class="string">"统计"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"about"</span>&gt;</span>关于本页<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ul><p>在form标签中添加action=”count”</p><ul><li><p>增加count.html文件</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>统计结果<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h1</span>&gt;</span>统计结果，总字数为&#123;&#123;count&#125;&#125;字<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h2</span>&gt;</span>你的文本<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line">&#123;&#123;text&#125;&#125;</span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>配置urls.py文件</p></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180902/lb0k2d8dHi.png?imageslim" alt="mark"></p><ul><li>在function中新增count函数<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count</span><span class="params">(request)</span>:</span></span><br><span class="line">    user_text = request.GET[<span class="string">'text'</span>] <span class="comment">##获取用户输入的文字</span></span><br><span class="line">    total_count = len(user_text)  <span class="comment">##统计字数</span></span><br><span class="line">    <span class="keyword">return</span> render(request,<span class="string">'count.html'</span>,&#123;<span class="string">'count'</span>:total_count,<span class="string">'text'</span>:user_text&#125;)</span><br></pre></td></tr></table></figure></li></ul><p>在这里需要注意的是我们通过render函数向html传递参数的时候需要以字典的形式传递。<br><strong>{‘count’:total_count,’text’:user_text}</strong></p><p>如果没有出错的话，当你点击统计之后会跳转到这个页面<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180902/lD873LF5H4.png?imageslim" alt="mark"></p><h3 id="字数统计"><a href="#字数统计" class="headerlink" title="字数统计"></a>字数统计</h3><p>完整的count函数代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count</span><span class="params">(request)</span>:</span></span><br><span class="line">    user_text = request.GET[<span class="string">'text'</span>]</span><br><span class="line">    user_text1 = request.GET[<span class="string">'text'</span>]</span><br><span class="line">    user_text = re.findall(<span class="string">'[\u4e00-\u9fa5]'</span>, user_text, re.S) <span class="comment">##用正则表达式去掉符号以及数字</span></span><br><span class="line">    total_count=len(user_text)</span><br><span class="line"></span><br><span class="line">    word_dict = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> user_text:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> word_dict:</span><br><span class="line">            word_dict[word] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            word_dict[word] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    dataframe = pd.DataFrame(list(word_dict.keys()), columns=[<span class="string">'字'</span>])</span><br><span class="line">    dataframe[<span class="string">'频次'</span>] = pd.DataFrame(list(word_dict.values()))</span><br><span class="line">    dataframe.sort_values(<span class="string">'频次'</span>, inplace=<span class="keyword">True</span>, ascending=<span class="keyword">False</span>)</span><br><span class="line">    old_width = pd.get_option(<span class="string">'display.max_colwidth'</span>) <span class="comment">##因为dataframe太长的话会显示不全，所以需要新增以下代码</span></span><br><span class="line">    pd.set_option(<span class="string">'display.max_colwidth'</span>, <span class="number">-1</span>)</span><br><span class="line">    dataframe = dataframe.to_html(escape=<span class="keyword">False</span>, index=<span class="keyword">False</span>, sparsify=<span class="keyword">True</span>, border=<span class="number">0</span>, index_names=<span class="keyword">False</span>, header=<span class="keyword">False</span>)</span><br><span class="line">    pd.set_option(<span class="string">'display.max_colwidth'</span>, old_width)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> render(request , <span class="string">'count.html'</span>,&#123;<span class="string">'count'</span>:total_count , <span class="string">'text'</span>:user_text1,<span class="string">'dict'</span>:dataframe&#125;)</span><br></pre></td></tr></table></figure><p>上面的代码就是把用户输入的文字通过循环的方式统计字数，然后把字典转换成dataframe,传递给html。</p><ul><li>完整的count.html</li></ul><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>统计结果<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h1</span>&gt;</span>统计结果，总字数为&#123;&#123;count&#125;&#125;字<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h2</span>&gt;</span>你的文本<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line">&#123;&#123;text&#125;&#125;</span><br><span class="line"><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">&#123;% autoescape off %&#125;</span><br><span class="line">&#123;&#123;dict&#125;&#125;</span><br><span class="line">&#123;% endautoescape %&#125;</span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">".."</span>&gt;</span>回到主页<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="关于django自动转义"><a href="#关于django自动转义" class="headerlink" title="关于django自动转义"></a>关于django自动转义</h3><p>Django的模板中会对HTML标签和JS等语法标签进行自动转义，原因显而易见，这样是为了安全。但是有的时候我们可能不希望这些HTML元素被转义，比如我们做一个内容管理系统，后台添加的文章中是经过修饰的，这些修饰可能是通过一个类似于FCKeditor编辑加注了HTML修饰符的文本，如果自动转义的话显示的就是保护HTML标签的源文件。为了在Django中关闭HTML的自动转义有两种方式，如果是一个单独的变量我们可以通过过滤器“|safe”的方式告诉Django这段代码是安全的不必转义。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&lt;p&gt;这行代表会被自动转义&lt;/p&gt;: &#123;&#123; data &#125;&#125;</span><br><span class="line">&lt;p&gt;这行代表不会被自动转义&lt;/p&gt;: &#123;&#123; data|safe &#125;&#125;</span><br></pre></td></tr></table></figure><p>其中第二行我们关闭了Django的自动转义。<br>我们还可以通过<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;%autoescape off%&#125;</span><br></pre></td></tr></table></figure></p><p>的方式关闭整段代码的自动转义，比如下面这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&#123;% autoescape off %&#125;</span><br><span class="line">    Hello &#123;&#123; name &#125;&#125;</span><br><span class="line">&#123;% endautoescape %&#125;</span><br></pre></td></tr></table></figure><h2 id="增加about页面"><a href="#增加about页面" class="headerlink" title="增加about页面"></a>增加about页面</h2><p>我们需要新增一个about页面用于告诉用户，我们这个页面是用来干什么的,步骤与之前的都差不多。</p><ul><li><p>增加about.html</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>关于本页<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h1</span>&gt;</span>关于本页<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h2</span>&gt;</span>本网站可以统计字数，并且会按频次降序排列<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">".."</span>&gt;</span>回到主页<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>配置urls.py文件<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180902/mEG20dic17.png?imageslim" alt="mark"> </p></li><li><p>配置function文件，新增about函数</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">about</span><span class="params">(request)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> render(request ,<span class="string">'about.html'</span>)</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180902/FdjaaGjf1L.png?imageslim" alt="mark"></p><p>在这里一个简单的字数统计网站就搭建好啦！<br>完整项目代码:<a href="https://github.com/dik111/word_count" target="_blank" rel="noopener">https://github.com/dik111/word_count</a></p><hr>]]></content>
    
    <summary type="html">
    
      这个django一个简单的入门教程
    
    </summary>
    
      <category term="网站搭建" scheme="http://yoursite.com/categories/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="网站搭建" scheme="http://yoursite.com/tags/%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/"/>
    
      <category term="django" scheme="http://yoursite.com/tags/django/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习笔记-4 Brief Introduction of Deep Learning；深度学习简介</title>
    <link href="http://yoursite.com/2018/07/30/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-4-Brief-Introduction-of-Deep-Learning%EF%BC%9B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/"/>
    <id>http://yoursite.com/2018/07/30/李宏毅机器学习笔记-4-Brief-Introduction-of-Deep-Learning；深度学习简介/</id>
    <published>2018-07-30T14:21:12.000Z</published>
    <updated>2018-12-09T04:07:43.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><p><img src="https://" alt="" style="width:100%"></p><a id="more"></a><h1 id="Three-Steps-for-Deep-Learning"><a href="#Three-Steps-for-Deep-Learning" class="headerlink" title="Three Steps for Deep Learning"></a>Three Steps for Deep Learning</h1><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180730/5E3a3iA3ma.png?imageslim" alt="mark"></p><h2 id="Step-1-Neural-Network"><a href="#Step-1-Neural-Network" class="headerlink" title="Step 1: Neural Network"></a>Step 1: Neural Network</h2><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180730/h2B725DEj7.png?imageslim" alt="mark"></p><h2 id="1212"><a href="#1212" class="headerlink" title="1212"></a>1212</h2><hr>]]></content>
    
    <summary type="html">
    
      这是最近学习李宏毅老师机器学习入门的第四篇学习笔记
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习笔记-3 Classification,Logistic Regression</title>
    <link href="http://yoursite.com/2018/07/26/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-3-Classification%E3%80%81Logistic-Regression/"/>
    <id>http://yoursite.com/2018/07/26/李宏毅机器学习笔记-3-Classification、Logistic-Regression/</id>
    <published>2018-07-26T14:23:06.000Z</published>
    <updated>2018-12-09T04:08:15.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><p><img src="https://" alt="" style="width:100%"></p><a id="more"></a><h1 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h1><p>分类算法在我们日常生活中随处可见：</p><ul><li>Credit Scoring<br>Input: income, savings, profession, age, past financial history ……<br>Output: accept or refuse</li><li>Medical Diagnosis<br>Input: current symptoms, age, gender, past medical history ……<br>Output: which kind of diseases</li><li>Handwritten character recognition<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180728/AkGlIbdGgc.png?imageslim" alt="mark"></li><li>Face recognition<br>Input: image of a face<br>output: person</li></ul><h2 id="Example-Application"><a href="#Example-Application" class="headerlink" title="Example Application"></a>Example Application</h2><p>在这节课程中，李宏毅老师通过宝可梦的HP值，Attack值，SP Atk值，SP Def值，Speed值等一系列值来预测宝可梦属于哪种类型。<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180728/8099K1GAfJ.png?imageslim" alt="mark"></p><h2 id="How-to-do-Classification"><a href="#How-to-do-Classification" class="headerlink" title="How to do Classification?"></a>How to do Classification?</h2><ul><li>Traning data for Classification<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180728/c26cgkJhEK.png?imageslim" alt="mark"></li></ul><h3 id="Classification-as-Regression"><a href="#Classification-as-Regression" class="headerlink" title="Classification as Regression?"></a>Classification as Regression?</h3><p>Binary classification as example<br>Training: Class 1 means the target is 1; Class 2 means the target is -1<br>Testing: closer to 1 → class 1; closer to -1 → class 2 </p><h2 id="Ideal-Alternatives-理想的替代品"><a href="#Ideal-Alternatives-理想的替代品" class="headerlink" title="Ideal Alternatives(理想的替代品)"></a>Ideal Alternatives(理想的替代品)</h2><ul><li>Function (Model):<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180728/egL5b6jCl3.png?imageslim" alt="mark"></li><li>Loss function:<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180728/f61LhjE1D9.png?imageslim" alt="mark"></li><li>Find the best funcion:<br>Example:Perceptron , SVM<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180728/ldDGiKk3Ei.png?imageslim" alt="mark"><br>在这里我们用线性回归算法进行分类，我们把接近-1的数据定义为class2,把接近1的数据定义为class1，以此作为分类，可以看到当数据远大于1时，绿色的直线慢慢往紫色的直线靠近了，因此在某种情况下，用线性回归进行分类可能会不太准确。<h2 id="Naive-Bayes"><a href="#Naive-Bayes" class="headerlink" title="Naive Bayes"></a>Naive Bayes</h2><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180728/cAl19gA77A.png?imageslim" alt="mark"><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180728/690BGedG7C.png?imageslim" alt="mark"><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180728/dmikm1mgLD.png?imageslim" alt="mark"><br>其中 <strong>mean μ</strong> 和 <strong>covariance matrix ∑</strong> 是决定形状的两个因素，而不同的参数，会有不同的形状：<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180728/dj87mK6dmc.png?imageslim" alt="mark"></li></ul><h2 id="Probability-from-Class"><a href="#Probability-from-Class" class="headerlink" title="Probability from Class"></a>Probability from Class</h2><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/h0m7DD8CmL.png?imageslim" alt="mark"></p><h3 id="那如何找到这个Gaussion-function呢？"><a href="#那如何找到这个Gaussion-function呢？" class="headerlink" title="那如何找到这个Gaussion function呢？"></a>那如何找到这个Gaussion function呢？</h3><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/jD3Eg7eici.png?imageslim" alt="mark"><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/L1cLAB0cDK.png?imageslim" alt="mark"></p><h2 id="Summery"><a href="#Summery" class="headerlink" title="Summery"></a>Summery</h2><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/DF3L2L9aFA.png?imageslim" alt="mark"></p><h2 id="Probability-Distribution"><a href="#Probability-Distribution" class="headerlink" title="Probability Distribution"></a>Probability Distribution</h2><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/2FHlmfB0FI.png?imageslim" alt="mark"></p><h1 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h1><h2 id="The-steps-of-Logistic-Regression"><a href="#The-steps-of-Logistic-Regression" class="headerlink" title="The steps of Logistic Regression"></a>The steps of Logistic Regression</h2><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/C3kCa0d4Cd.png?imageslim" alt="mark"><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/a7F5I1i9FJ.png?imageslim" alt="mark"><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/9A96DEL9IL.png?imageslim" alt="mark"></p><h2 id="Logistic-Regression-VS-Linear-Regression"><a href="#Logistic-Regression-VS-Linear-Regression" class="headerlink" title="Logistic Regression VS Linear Regression"></a>Logistic Regression VS Linear Regression</h2><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/cB393jDfIJ.png?imageslim" alt="mark"></p><h2 id="为什么不能用Logistic-Regression-Square-Error"><a href="#为什么不能用Logistic-Regression-Square-Error" class="headerlink" title="为什么不能用Logistic Regression+Square Error"></a>为什么不能用Logistic Regression+Square Error</h2><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/f9kHgKj4Bd.png?imageslim" alt="mark"></p><h2 id="Cross-Entropy-v-s-Square-Error"><a href="#Cross-Entropy-v-s-Square-Error" class="headerlink" title="Cross Entropy v.s. Square Error"></a>Cross Entropy v.s. Square Error</h2><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/B8aFe713FJ.png?imageslim" alt="mark"></p><h2 id="Discriminative（Logstic）-v-s-Generative（Gaussion）"><a href="#Discriminative（Logstic）-v-s-Generative（Gaussion）" class="headerlink" title="Discriminative（Logstic） v.s. Generative（Gaussion）"></a>Discriminative（Logstic） v.s. Generative（Gaussion）</h2><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/BjFceKIEFF.png?imageslim" alt="mark"><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/bkh0iBek86.png?imageslim" alt="mark"><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/GGegFb7ECH.png?imageslim" alt="mark"></p><h2 id="Multi-class-Classification"><a href="#Multi-class-Classification" class="headerlink" title="Multi-class Classification"></a>Multi-class Classification</h2><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/74i9FEki8K.png?imageslim" alt="mark"><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/KHa7mdjfg4.png?imageslim" alt="mark"></p><h2 id="Limitation-of-Logistic-Regression"><a href="#Limitation-of-Logistic-Regression" class="headerlink" title="Limitation of Logistic Regression"></a>Limitation of Logistic Regression</h2><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/2C76EfHHIk.png?imageslim" alt="mark"><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/AadIi6ge6E.png?imageslim" alt="mark"><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/7bB6beKdgH.png?imageslim" alt="mark"><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/181m216d0J.png?imageslim" alt="mark"><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/1I8ACL4525.png?imageslim" alt="mark"><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180729/bF173Hj86c.png?imageslim" alt="mark"></p><hr>]]></content>
    
    <summary type="html">
    
      这是最近学习李宏毅老师机器学习入门的第三篇学习笔记
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>梯度下降算法实战</title>
    <link href="http://yoursite.com/2018/06/29/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95%E5%AE%9E%E6%88%98/"/>
    <id>http://yoursite.com/2018/06/29/梯度下降算法实战/</id>
    <published>2018-06-29T13:58:27.000Z</published>
    <updated>2018-12-09T04:07:28.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><p><img src="https://" alt="" style="width:100%"><br>在上一篇文章中，我们了解了梯度下降算法的原理，那么在这一篇文章中，我们将结合李宏毅机器学习入门的课后作业1，用python来实现梯度下降。<br><a id="more"></a></p><p><em>课后作业1内容&amp;数据集链接地址：<a href="https://ntumlta.github.io/2017fall-ml-hw1" target="_blank" rel="noopener">https://ntumlta.github.io/2017fall-ml-hw1</a></em></p><h2 id="载入数据"><a href="#载入数据" class="headerlink" title="载入数据"></a>载入数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.set_style(<span class="string">'darkgrid'</span>) <span class="comment">#设定绘图的背景样式</span></span><br><span class="line">sns.set_palette(<span class="string">'muted'</span>) <span class="comment">#设定图表的颜色板</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">'train.csv'</span>,encoding=<span class="string">'big5'</span>)<span class="comment">#用pandas读取csv文件</span></span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180629/ii813hcGJa.png?imageslim" alt="mark"><br>可以看到tranning set由这样的数据组成，我们的目标就是通过AMB_TEMP,CH4等一系列数据，预估出PM2.5的值。</p><h2 id="数据清洗-amp-处理"><a href="#数据清洗-amp-处理" class="headerlink" title="数据清洗&amp;处理"></a>数据清洗&amp;处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">del</span> data[<span class="string">'datetime'</span>] <span class="comment">#删除无用指标datetime</span></span><br><span class="line"><span class="keyword">del</span> data[<span class="string">'item'</span>]<span class="comment">#删除无用指标item</span></span><br><span class="line">data.set_index([<span class="string">'obvservations'</span>],inplace=<span class="keyword">True</span>) </span><br><span class="line">data6 = pd.DataFrame()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">240</span>):<span class="comment">#数据处理</span></span><br><span class="line">    data3 = data.iloc[i*<span class="number">18</span>:(i+<span class="number">1</span>)*<span class="number">18</span>,:]</span><br><span class="line">    data4 = data.iloc[(i+<span class="number">1</span>)*<span class="number">18</span>:(i+<span class="number">2</span>)*<span class="number">18</span>,:]</span><br><span class="line">    data5 = pd.concat([data3,data4],axis=<span class="number">1</span>)</span><br><span class="line">    data6 = pd.concat([data5,data6],axis = <span class="number">1</span>)</span><br><span class="line">data7 = data6.T</span><br><span class="line">data8 = data7.dropna(how = <span class="string">'all'</span>)</span><br><span class="line"><span class="keyword">del</span> data8[<span class="string">'RAINFALL'</span>]</span><br><span class="line">data9 = pd.DataFrame(data8,dtype=<span class="string">'float'</span>)</span><br></pre></td></tr></table></figure><p>经过一番处理之后，数据变成了这样的形式：<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180629/2DEL9GHGEC.png?imageslim" alt="mark"></p><h2 id="描述性分析"><a href="#描述性分析" class="headerlink" title="描述性分析"></a>描述性分析</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">'AMB_TEMP'</span>)</span><br><span class="line">plt.scatter(data9[<span class="string">'AMB_TEMP'</span>],data9[<span class="string">'PM2.5'</span>])</span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">'CH4'</span>)</span><br><span class="line">plt.scatter(data9[<span class="string">'CH4'</span>],data9[<span class="string">'PM2.5'</span>])</span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">plt.title(<span class="string">'CO'</span>)</span><br><span class="line">plt.scatter(data9[<span class="string">'CO'</span>],data9[<span class="string">'PM2.5'</span>])</span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">plt.title(<span class="string">'NMHC'</span>)</span><br><span class="line">plt.scatter(data9[<span class="string">'NMHC'</span>],data9[<span class="string">'PM2.5'</span>])</span><br></pre></td></tr></table></figure><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180629/Bk1jclj7G8.png?imageslim" alt="mark"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">'NO'</span>)</span><br><span class="line">plt.scatter(data9[<span class="string">'NO'</span>],data9[<span class="string">'PM2.5'</span>])</span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">'NO2'</span>)</span><br><span class="line">plt.scatter(data9[<span class="string">'NO2'</span>],data9[<span class="string">'PM2.5'</span>])</span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">plt.title(<span class="string">'NOx'</span>)</span><br><span class="line">plt.scatter(data9[<span class="string">'NOx'</span>],data9[<span class="string">'PM2.5'</span>])</span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">plt.title(<span class="string">'O3'</span>)</span><br><span class="line">plt.scatter(data9[<span class="string">'O3'</span>],data9[<span class="string">'PM2.5'</span>])</span><br></pre></td></tr></table></figure></p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180629/IFImJ61K72.png?imageslim" alt="mark"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">'WD_HR'</span>)</span><br><span class="line">plt.scatter(data9[<span class="string">'WD_HR'</span>],data9[<span class="string">'PM2.5'</span>])</span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">'WIND_DIREC'</span>)</span><br><span class="line">plt.scatter(data9[<span class="string">'WIND_DIREC'</span>],data9[<span class="string">'PM2.5'</span>])</span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">plt.title(<span class="string">'WIND_SPEED'</span>)</span><br><span class="line">plt.scatter(data9[<span class="string">'WIND_SPEED'</span>],data9[<span class="string">'PM2.5'</span>])</span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">plt.title(<span class="string">'WS_HR'</span>)</span><br><span class="line">plt.scatter(data9[<span class="string">'WS_HR'</span>],data9[<span class="string">'PM2.5'</span>])</span><br></pre></td></tr></table></figure></p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180629/66EJIbmCIA.png?imageslim" alt="mark"></p><ul><li>相关度计算<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">internal_chars =[<span class="string">'AMB_TEMP'</span>,<span class="string">'CH4'</span>,<span class="string">'CO'</span>,<span class="string">'NMHC'</span>,<span class="string">'NO'</span>,<span class="string">'NO2'</span>,<span class="string">'NOx'</span>,<span class="string">'O3'</span>,<span class="string">'PM10'</span>,<span class="string">'PM2.5'</span>,<span class="string">'RH'</span>,<span class="string">'SO2'</span>,<span class="string">'THC'</span>,<span class="string">'WD_HR'</span>,<span class="string">'WIND_DIREC'</span>,<span class="string">'WIND_SPEED'</span>,<span class="string">'WS_HR'</span>,]</span><br><span class="line">corrmat = data9[internal_chars].corr() <span class="comment">#计算相关系数</span></span><br><span class="line">f , ax = plt.subplots(figsize = (<span class="number">20</span>,<span class="number">12</span>)) <span class="comment">#设置图标尺寸大小</span></span><br><span class="line">plt.xticks(rotation = <span class="string">'0'</span>)</span><br><span class="line">sns.heatmap(corrmat, square=<span class="keyword">False</span>, linewidths=<span class="number">.8</span>, annot=<span class="keyword">True</span>) <span class="comment">#设置热力图参数</span></span><br></pre></td></tr></table></figure></li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180629/19I32HD7Ae.png?imageslim" alt="mark"></p><h2 id="建模分析-预测PM2-5"><a href="#建模分析-预测PM2-5" class="headerlink" title="建模分析-预测PM2.5"></a>建模分析-预测PM2.5</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">X = data9[[<span class="string">'PM10'</span>,<span class="string">'NO2'</span>]]</span><br><span class="line">y = data9[[<span class="string">'PM2.5'</span>]]</span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X = scaler.fit_transform(X)</span><br><span class="line">y = scaler.fit_transform(y)</span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=<span class="number">1</span>)</span><br><span class="line">clf = SGDRegressor(loss=<span class="string">'epsilon_insensitive'</span>,alpha=<span class="number">0.01</span>,penalty=<span class="string">'l2'</span>,max_iter=<span class="number">10000</span>,shuffle=<span class="keyword">True</span>,n_iter=np.ceil(<span class="number">10</span>**<span class="number">6</span>/<span class="number">8622</span>))</span><br><span class="line">clf.fit(X_train,y_train)</span><br><span class="line">clf.score(X,y)</span><br></pre></td></tr></table></figure><p>其中loss = ‘epsilon_insensitive’ 表示用的最小二乘法，alpha = 0.01表示为初始的步长,max_iter=10000表示最大的迭代次数。最后模型的评分为0.62分，可能是数据量有点太少了，在以后的文章中，会继续把它优化！</p><hr>]]></content>
    
    <summary type="html">
    
      用python实现梯度下降算法！
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>李宏毅机器学习笔记-2 （Regression：Case Study ；回归：案例研究）</title>
    <link href="http://yoursite.com/2018/06/26/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-2-%EF%BC%88Regression%EF%BC%9ACase-Study-%EF%BC%9B%E5%9B%9E%E5%BD%92%EF%BC%9A%E6%A1%88%E4%BE%8B%E7%A0%94%E7%A9%B6%EF%BC%89/"/>
    <id>http://yoursite.com/2018/06/26/李宏毅机器学习笔记-2-（Regression：Case-Study-；回归：案例研究）/</id>
    <published>2018-06-26T14:36:43.000Z</published>
    <updated>2018-12-09T04:08:27.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><a id="more"></a><h2 id="Regression-pokemons"><a href="#Regression-pokemons" class="headerlink" title="Regression-pokemons"></a>Regression-pokemons</h2><p>李老师在这一节课程开始介绍了用Regression，预测预测宝可梦（<br>pokemons）进化后过的CP值（战斗力）。<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180626/DbEKa15F6H.png?imageslim" alt="mark"><br>我们的目标是找出上帝函数’f’,通过imput一只宝可梦进化前的cp值，output他进化后的cp值。</p><h2 id="Step1-选择Model"><a href="#Step1-选择Model" class="headerlink" title="Step1 选择Model"></a>Step1 选择Model</h2><p>在这里李老师建立以个Linear model:<br> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> y = b + w * x</span><br><span class="line">它是infinite的……</span><br><span class="line">可能为f1: y = <span class="number">10.0</span> + <span class="number">9.0</span> ∙ x</span><br><span class="line">可能为f2: y = <span class="number">9.8</span> + <span class="number">9.2</span> ∙ x</span><br><span class="line">可能为f3: y = - <span class="number">0.8</span> - <span class="number">1.2</span> ∙ x</span><br><span class="line">……</span><br></pre></td></tr></table></figure></p><p>不同的b和w都会得到不同的f，而我们的目标就是找出一个最合适的f。</p><h2 id="Step2-Goodness-of-function"><a href="#Step2-Goodness-of-function" class="headerlink" title="Step2 Goodness of function"></a>Step2 Goodness of function</h2><p>当我们将准备好的training data（已知10个宝可梦的进化情况），建立一个二维坐标轴。<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180627/ag4Ch54Im0.png?imageslim" alt="mark"></p><p>通过上图可以看出，似乎有一个函数能够拟合这些坐标点，而这就是我们想要的，为了选出最契合的 f ，我们要建立一个Loss function L ，也就是函数的函数。</p><ul><li>如果我们将 f 的 w 和 b 作为两轴，则在下图中每一点都代表一个 function f ，而颜色代表output的大小，也就代表该function f 参数的好坏。易理解，smallest点做对应的函数 f 就是我们想要的。</li></ul><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180627/f9FiG60Ab3.png?imageslim" alt="mark"></p><h2 id="Step3-Best-Function"><a href="#Step3-Best-Function" class="headerlink" title="Step3 Best Function"></a>Step3 Best Function</h2><p>在lossfuction建立之后，我们需要通过这些这些lossfuction找到最合适的Best fuction,在这里，我们通过线性代数的基本公式来直接计算出最佳的w和b。</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180627/BhlKFH27KE.png?imageslim" alt="mark"><br>这种方法适用于单一特征的问题，但现实中，我们的问题往往是涉及到多个特征的，这时，则需要我们用更有效fuction,这里，李老师介绍了梯度下降法进行计算。<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180627/j68LdEI3dI.png?imageslim" alt="mark"><br>首先我们需要随机选取一个w0,计算其斜率，如果为正，则减小w，如果为负，则增大w。而这有另一个问题，每次要增加或减少多少w值呢，有两个因素影响。第一，即微分值，如果微分值很大或很小，表示此处非常陡峭，那么证明距离最低点还有很远的距离，所以移动的距离就很大。第二个因素是我们事先自主定义的常数项 η 值，即步长。<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180627/c0fikGF2DA.png?imageslim" alt="mark"></p><p>经过无数次迭代之后，参数会经过无数次更新，最终到达一个最低值。而当我们有多个feature时，即不仅有w和b时，同样不会影响梯度下降过程，其原理为：</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180627/i3eBFegkbg.png?imageslim" alt="mark"></p><h2 id="How’s-the-results"><a href="#How’s-the-results" class="headerlink" title="How’s the results?"></a>How’s the results?</h2><p>经过上面的步骤后，我们得到了一个函数f，但我们发现并不是所有数据都能很好的拟合函数，这就会造成很大的预测不准的情况，通过Loss Function也能看出，最优解的值依然很大，测试数据的表现也不好，所以我们就要想办法优化。</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180627/9IKDCEfK56.png?imageslim" alt="mark"></p><p>很容易想到，刚刚我们用了一次方程作为model，二次方程会不会更好一些呢，三次方程、四次方程呢？于是我们做了以下实验，用同样的方法，放到多次方程中。</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180627/L4Gh3cgfm7.png?imageslim" alt="mark"><br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180627/Ae4g6bEfKK.png?imageslim" alt="mark"></p><h2 id="overfitting"><a href="#overfitting" class="headerlink" title="overfitting"></a>overfitting</h2><p>从上面的4幅图可以看出，虽然我们增加了函数次数后，可以使得training set 的error越来越小，但是test set的error并没有随着次数的增大而减小，甚至到5次时，结果大大超出了我们的预估，那么这种现象就叫做overfitting。</p><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180627/C7C7Ad87eD.png?imageslim" alt="mark"></p><p>由此可见，fuction并不是越复杂越好，我们需要根据实际情况来选择合适的fuction，而对于overfitting的应对办法，我们一般采用以下方法来解决：</p><ul><li>增加新特征，可以考虑加入进特征组合、高次特征，来增大假设空间;</li><li>尝试非线性模型，比如核SVM 、决策树、DNN等模型;</li><li>如果有正则项可以较小正则项参数 λ</li><li>Boosting ,Boosting 往往会有较小的 Bias，比如 Gradient Boosting 等.</li></ul><h2 id="underfitting"><a href="#underfitting" class="headerlink" title="underfitting"></a>underfitting</h2><p><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180627/DHJj85dL4K.png?imageslim" alt="mark"><br>有过拟合当然也少不了欠拟合了，对于欠拟合,我们一般采用以下方法解决：</p><ul><li>增加新特征，可以考虑加入进特征组合、高次特征，来增大假设空间;</li><li>尝试非线性模型，比如核SVM 、决策树、DNN等模型;</li><li>如果有正则项可以较小正则项参数 λ.</li><li>Boosting ,Boosting 往往会有较小的 Bias，比如 Gradient Boosting 等.</li></ul><h2 id="交叉检验"><a href="#交叉检验" class="headerlink" title="交叉检验"></a>交叉检验</h2><p>当数据比较少是，留出一部分做交叉检验可能比较奢侈，还有只执行一次训练-测试来评估模型，会带有一些随机性，这些缺点都可以通过交叉检验克服，交叉检验对数据的划分如下：<br><img src="https://dik111-1258101294.cos.ap-guangzhou.myqcloud.com/blog/180627/Cc02gFb7aE.png?imageslim" alt="mark"></p><h3 id="交叉检验的步骤："><a href="#交叉检验的步骤：" class="headerlink" title="交叉检验的步骤："></a>交叉检验的步骤：</h3><ol><li>将数据分类训练集、验证集、测试集；</li><li>选择模型和训练参数；</li><li>使用训练集训练模型，在验证集中评估模型；</li><li>针对不同的模型，重复2）- 3）的过程；</li><li>选择最佳模型，使用训练集和验证集一起训练模型；</li><li>使用测试集来最终测评模型。</li></ol><h2 id="关于正则"><a href="#关于正则" class="headerlink" title="关于正则"></a>关于正则</h2><p>在模型的损失函数中引入正则项，可用来防止过拟合，于是得到的优化形式如下：</p><script type="math/tex; mode=display">w^*=argminwL(y,f(w,x))+λΩ(w)</script><p>这里 Ω(w) 即为正则项， λ  则为正则项的参数，通常为 Lp 的形式，即：</p><script type="math/tex; mode=display">Ω(w)=||w||^p</script><p>实际应用中比较多的是 L1 与 L2 正则，L1 正则是 L0 正则的凸近似，这里 L0 正则即为权重参数 w 中值为 0 的个数，但是求解 L0 正则是个NP 难题，所以往往使用 L1 正则来近似 L0 , 来使得某些特征权重为 0 ，这样便得到了稀疏的的权重参数 w。</p><p>在下一篇的文章我会结合李宏毅老师的课后作业，用python实现梯度下降算法，敬请期待！</p><p>相关参考：<br><a href="https://blog.csdn.net/soulmeetliang/article/details/72619885" target="_blank" rel="noopener">https://blog.csdn.net/soulmeetliang/article/details/72619885</a><br><a href="https://www.cnblogs.com/ooon/p/5715918.html" target="_blank" rel="noopener">https://www.cnblogs.com/ooon/p/5715918.html</a></p><hr>]]></content>
    
    <summary type="html">
    
      这是最近学习李宏毅老师机器学习入门的第一篇学习笔记。
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Pandas入门简介</title>
    <link href="http://yoursite.com/2017/10/25/Pandas%E5%85%A5%E9%97%A8%E7%AE%80%E4%BB%8B/"/>
    <id>http://yoursite.com/2017/10/25/Pandas入门简介/</id>
    <published>2017-10-25T08:15:49.000Z</published>
    <updated>2019-02-10T09:18:32.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><p><img src="https://" alt="" style="width:100%"></p><a id="more"></a><h2 id="Pandas简介"><a href="#Pandas简介" class="headerlink" title="Pandas简介"></a>Pandas简介</h2><p>pandas 是基于NumPy 的一种工具，该工具是为了解决数据分析任务而创建的。pandas提供了大量能使我们快速便捷地处理数据的函数和方法。你很快就会发现，它是使Python成为强大而高效的数据分析环境的重要因素之一。<br>pandas主要使用的是两个数据结构Series和Dataframe,我们先导入它们以及相关模块：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> Series, DataFrame</span><br></pre></td></tr></table></figure><h2 id="Pandas数据结构：Series"><a href="#Pandas数据结构：Series" class="headerlink" title="Pandas数据结构：Series"></a>Pandas数据结构：Series</h2><p>一般来说，Series可以被认为是一维数组，Series与一维数组最主要的区别是Series具有索引（index），可以与另一个程序中常见的数据结构联系起来。</p><h3 id="Series的创建"><a href="#Series的创建" class="headerlink" title="Series的创建"></a>Series的创建</h3><p>创建Series的基本格式是s = Series(data, index=index, name=name)，下面给出几个创建Series的例子。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = np.random.randn(<span class="number">5</span>)</span><br><span class="line"><span class="keyword">print</span> （<span class="string">"a is an array:"</span>）</span><br><span class="line"><span class="keyword">print</span> （a）</span><br><span class="line">s = Series(a)</span><br><span class="line"><span class="keyword">print</span> （<span class="string">"s is a Series:"</span>）</span><br><span class="line"><span class="keyword">print</span> （s）</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a is an array:</span><br><span class="line">[-1.24962807 -0.85316907  0.13032511 -0.19088881  0.40475505]</span><br><span class="line">s is a Series:</span><br><span class="line">0   -1.249628</span><br><span class="line">1   -0.853169</span><br><span class="line">2    0.130325</span><br><span class="line">3   -0.190889</span><br><span class="line">4    0.404755</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><p>在创建Series时可以添加index，而且可以使用Series.index查看具体的index，但是需要注意的一点是，当从数组创建Series时，若指定index，那么index长度要和data的长度一致：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">s = Series(np.random.randn(<span class="number">5</span>), index = [<span class="string">'a'</span> , <span class="string">'b'</span> , <span class="string">'c'</span> , <span class="string">'d'</span> , <span class="string">'e'</span>])</span><br><span class="line">print(s)</span><br><span class="line">print(s.index)</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a   -0.566972</span><br><span class="line">b   -0.426072</span><br><span class="line">c    0.787193</span><br><span class="line">d    0.526550</span><br><span class="line">e   -1.271557</span><br><span class="line">dtype: float64</span><br><span class="line">Index([&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;], dtype=&apos;object&apos;)</span><br></pre></td></tr></table></figure><p>Series还可以从字典（dict）创建：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;<span class="string">'a'</span> : <span class="number">0.</span> , <span class="string">'b'</span> : <span class="number">1.</span> , <span class="string">'c'</span> : <span class="number">2</span>&#125;</span><br><span class="line">print(<span class="string">"d is a dict:"</span>)</span><br><span class="line">print(d)</span><br><span class="line">s = Series(d)</span><br><span class="line">print( <span class="string">"s is a Series:"</span>)</span><br><span class="line">print(s)</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">d is a dict:</span><br><span class="line">&#123;&apos;a&apos;: 0.0, &apos;b&apos;: 1.0, &apos;c&apos;: 2&#125;</span><br><span class="line">s is a Series:</span><br><span class="line">a    0.0</span><br><span class="line">b    1.0</span><br><span class="line">c    2.0</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure><h1 id=""><a href="#" class="headerlink" title="#"></a>#</h1><hr>]]></content>
    
    <summary type="html">
    
      这是一篇pandas用法的入门文章
    
    </summary>
    
      <category term="数据分析" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="数据分析" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
</feed>
